{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/portfolio/week8.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/NLP_.png\" width=\"700px\" height=\"400px\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorization\n",
    "### What is vector?\n",
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/scalar-vector-matrix.jpeg\" width='400px' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of word representation\n",
    "- Scalar: a single variable\n",
    "- One-hot encoding vector: ~ dummy variables\n",
    "- Distributed embedding vector: word2vec & glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "- Equivalent to dummy variables\n",
    "- Apple: [1,0,0]; Banana: [0,1,0]; Grape: [0,0,1]\n",
    "- A basket of fruit: one apple, one banana and one grape: [1,1,1]\n",
    "\n",
    "#### Document-Term Matrix\n",
    "- Row: Document\n",
    "- Column: Term\n",
    "- Row and column can be reversed.\n",
    "- In the cell:\n",
    "    - Term Frequency (`tf`): absolute vs **relative**\n",
    "    - Term Frequency-Inversed Document Frequency (TF-IDF)\n",
    "        - to suppress undiscriminative words\n",
    "        - Doc Freq (`df`): absolute vs **relative**\n",
    "        - Formula: `tf*log(1/df) = tf*log(N/n)`\n",
    "\n",
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/doc-term-matrix.jpg\" width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">1a. English Paragraph-Term Matrix (step-by-step breakdown)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first reload data_cleaning() function we created last week\n",
    "def data_cleaning(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[0-9]+','',text)\n",
    "    text=re.sub('@[^ ]+','',text)\n",
    "    text=re.sub('#[^ ]+','',text)\n",
    "    text=re.sub('http://[^ ]+|https://[^ ]+','',text)\n",
    "    text=re.sub('\\p{P}+',' ',text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load english stop words\n",
    "#stop words file: https://juniorworld.github.io/python-workshop-2018/doc/stop_words_eng.txt\n",
    "file_eng=open('FILE PATH','r')\n",
    "stop_words_eng=[]\n",
    "for line in file_eng.readlines():\n",
    "    line=line.strip() #remove line break\n",
    "    stop_words_eng.append(line) #update the list of stop words line by line\n",
    "file_eng.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_words_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a paragraph\n",
    "paragraph_1=\"Many of us campaigned on the same core promises: to defend American jobs and demand fair trade for American workers; to rebuild and revitalize our Nation's infrastructure; to reduce the price of healthcare and prescription drugs; to create an immigration system that is safe, lawful, modern and secure; and to pursue a foreign policy that puts America's interests first.\"\n",
    "cleaned_paragraph_1=    #clean the paragraph by using data_cleaning() function\n",
    "words_1=                #tokenize the paragraph\n",
    "cleaned_words_1=        #remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_words_1 #have a look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the word frequency table\n",
    "tf_1=pd.Series(cleaned_words_1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap previous lines into a user function which takes a paragraph string and outputs a frequency table\n",
    "def paragraph_to_tf(paragraph):\n",
    "    \n",
    "    \n",
    "    #WRITE YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    return(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use paragraph_to_tf() function to obtain term frequency table of paragraph_2\n",
    "paragraph_2=\"In 2019, we also celebrate 50 years since brave young pilots flew a quarter of a million miles through space to plant the American flag on the face of the moon. Half a century later, we are joined by one of the Apollo 11 astronauts who planted that flag: Buzz Aldrin. This year, American astronauts will go back to space on American rockets.\"\n",
    "tf_2=paragraph_to_tf(paragraph_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_combined=        #combine two frequency tables\n",
    "tf_combined=tf_combined.fillna(0) #replace missing value with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">1b. English Paragraph-Term Matrix (integrated)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. create term-doc matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the file of 2019 State of the Union addressed by President Trump\n",
    "file_2019=open('FILE PATH','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file line by line, obtain the term frequency table of each paragraph and combine them into a Paragraph-Term Matrix\n",
    "#REMINDER: pd.concat() doesn't support combining blank table\n",
    "#---------------------\n",
    "\n",
    "#WRITE YOUR CODE HERE\n",
    "\n",
    "#---------------------\n",
    "tf_combined=tf_combined.fillna(0) #replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#row sum\n",
    "tf_combined.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column sum\n",
    "tf_combined.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to calculate DF?\n",
    "tf_combined[tf_combined>0].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. remove words only appearing in one paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words that only appear in one paragraph\n",
    "tf_combined=tf_combined[tf_combined[tf_combined>0].sum(axis=1)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization: absolute term freq divided by total count of words in paragraph\n",
    "relative_tf=tf_combined/tf_combined.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "**<b>Extra Knowledge: HOW TO IMPLEMENT TF-IDF</b>**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python\n",
    "tf_idf=relative_tf.T * np.log(127/tf_combined[tf_combined>0].sum(axis=1))\n",
    "tf_idf.iloc[0].sort_values()[::-1] #look at the most distinguishing words in the last paragraph```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">1c. English Paragraph-Term Matrix (shortcut)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2019=open('FILE PATH','r',encoding='utf-8')\n",
    "paragraphs=file_2019.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(lowercase=True,stop_words='english')\n",
    "tf=vectorizer.fit_transform(paragraphs)\n",
    "tf=pd.DataFrame(tf.toarray().T,index=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape #results of this method will be different with that of previous method as the stop words list is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization: absolute freq to relative freq\n",
    "tf=tf/tf.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Break\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic & Frame Analysis: From a Word Co-occurrence perspective\n",
    "- RQ: How framing devices co-occur in a text and to form underlying patterns of meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/hierarchy.png\" width='700px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. From Doc-Term Matrix to Term-Term Co-occurrence Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have four sentences:\n",
    "- 'apple, banana'\n",
    "- 'apple, banana, grape'\n",
    "- 'banana, grape'\n",
    "- 'apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate into numbers\n",
    "sen1=[1,1,0]\n",
    "sen2=[1,1,1]\n",
    "sen3=[0,1,1]\n",
    "sen4=[1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: How many baskets have both apple and babana?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_METHOD 1: AND operator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0 #initialization\n",
    "for i in range(4): #go through every basket\n",
    "    if sen1[i]==1 and sen2[i]==1 and sen3[i]==1 and sen4[i]==1:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_METHOD 2: Multiply_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(4):\n",
    "    if sen1[i]*sen2[i]*sen3[i]*sen4[i]==1:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_METHOD 3: Dot product_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=np.matrix([sen1,sen2,sen3,sen4])\n",
    "np.dot(matrix.T,matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Multiplication\n",
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/vec-multiply.png\" align='left' width='300px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/matrix-multiply.svg\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    ">```python\n",
    "fruit2=np.matrix(\n",
    "      [[0,1,1,0],\n",
    "       [0,0,1,1],\n",
    "       [1,0,1,1]])```\n",
    "       \n",
    ">```python\n",
    "np.dot(fruit2,fruit2.T) = ?\n",
    "       ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using dot product\n",
    "tt_matrix=np.dot(relative_tf,relative_tf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix.shape #symmetric matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieve data from matrix: `matrix_name[row index, col index]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix[0,:] #full list of co-occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt_matrix[:5,:5]) #the co-occurrence matrix is symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Export Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix=pd.DataFrame(tt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix.index=relative_tf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix.columns=relative_tf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_matrix.to_csv('matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Clustering Analysis & Visualization\n",
    "We will use a very user-friendly software for network analysis: Gephi (download link: https://gephi.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/occurence-network.png\" width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "Please repeat previous steps and apply word occurrence analysis over 2019 Chinese government's annual report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the file of 2019 Government Annual Report addressed by Premier Li Keqiang\n",
    "chi_2019=open('FILE PATH','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
