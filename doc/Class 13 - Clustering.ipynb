{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering: KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris (<a href=\"https://archive.ics.uci.edu/ml/datasets/iris\">intro page</a>) is a widely used dataset for training basic machine learning models.<br>\n",
    "- The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. \n",
    "- Three Classes: Iris Setosa (0), Iris Versicolour (1), Iris Virginica (2) \n",
    "- Four Features: sepal length, sepal width, petal length, petal width\n",
    "<br>\n",
    "<table>\n",
    "    <tr><td><img src=\"https://archive.ics.uci.edu/ml/assets/MLimages/Large53.jpg\" width=\"200\"></td>\n",
    "        <td><img src=\"https://cdn.britannica.com/39/91239-004-44353E32/Diagram-flowering-plant.jpg\" width=\"250\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iris is a dictionary with several keys\n",
    "- \"data\": X, an array of iris biometrics\n",
    "    - array: a data type in numpy ≈ multi-dimensional list\n",
    "    - list ≈ one-dimensional array\n",
    "    >```python\n",
    "    #conversion\n",
    "    a=np.array([1,2,3])\n",
    "    b=list(a)\n",
    "    c=a.tolist()\n",
    "    ```\n",
    "    - First dimension: #observations\n",
    "    - Second dimension: #features\n",
    "    - Array reference: \n",
    "    >```python\n",
    "    a[row, col]\n",
    "        a[0,1] #sepal width of the first iris observation\n",
    "    a[start_row:end_row, col]\n",
    "        a[:5,1] #sepal widths of the first five iris observations\n",
    "        a[:,1] #sepal widths of all observations\n",
    "    a[row,start_col:end_col]\n",
    "        a[4,:2] #sepal lengths and sepal widths of the fifth observation\n",
    "        a[4,:] #all features about the fifth observation\n",
    "        a[4] #all features about the fifth observation\n",
    "    a[start_row:end_row, start_col:end_col]\n",
    "        a[:5,:2] #sepal lengths and sepal widths of the first five observations\n",
    "    ```\n",
    "- \"target\": Y, a list of iris classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['data'].shape #150 observations, 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "<img src=\"https://juniorworld.github.io/python-workshop/img/KMeans_Flowchart.png\" width=\"600\">\n",
    "\n",
    "- Purpose: cluster data points into K groups according to their locations and distances\n",
    "- Input: observation data, X\n",
    "- Output: group assignments, Y\n",
    "- Procedure:\n",
    "    - STEP 1. Intialize K cluster centroids\n",
    "        - centroids: mid points\n",
    "    - STEP 2. Calculate the distance between each data point and each centroid\n",
    "    - STEP 3. Assign data point to the cluster whose centroid is closest to it\n",
    "    - STEP 4. Update the cluster centroids with new group\n",
    "    - STEP 5. Repeat STEP 1~4 for specific time or until convergence \n",
    "- Exit condition: \n",
    "    - Designated number of runs is reached\n",
    "    - Group assignments of all observations do not change\n",
    "    - Model performance does not improve significantly\n",
    "    \n",
    "<img src=\"https://www.jeremyjordan.me/content/images/2016/12/kmeans.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: red\">1. Step-by-Step Breakdowns</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1. Initialize K cluster centroids\n",
    "- Randomly choose n value out of a list: `np.random.choice(list, n)`. It supports two modes of extraction:\n",
    "    - Extraction with replacement: an element CAN be selected multiple times\n",
    "    - Extraction without replacement: an element CANNOT be selected multiple times\n",
    "\n",
    ">```python\n",
    "np.random.choice(list, n) #Default: with replacement\n",
    "np.random.choice(list, n, True) #with replacement\n",
    "np.random.choice(list, n, False) #without replacement\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random draw with replacement\n",
    "np.random.choice([1,2,3,4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random draw with replacement\n",
    "np.random.choice([1,2,3,4], 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random draw without replacement\n",
    "np.random.choice([1,2,3,4], 2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we randomly choose 3 observations in iris['data'] as initial centroids using np.random.choice()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly pick 3 points as centroids\n",
    "random_centroids_index=np.random.choice(range(data.shape[0]),3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_centroids="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_centroids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2. Calculate the pairwise distance between data point and each centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) VECTOR NORM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop/img/vector_norm.png\" width=\"200px\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if U=(U1,U2,U3,...,Un), ‖U‖=sqrt(U1^2 + U2^2 + U3^2 +...+ Un^2)\n",
    "a=np.array([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=np.sqrt(sum(np.power(a,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHORTCUT: Use np.linalg.norm() to calculate the vector norm\n",
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) PAIRWISE DISTANCE: VECTOR SUBTRACTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop/img/vector_minus.png\" width=\"250px\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([0,1])\n",
    "b=np.array([0,2])\n",
    "np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the pairwise distance between first data point and first cluster's centroid\n",
    "np.linalg.norm(data[0]-random_centroids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Operations on Array\n",
    "- Array and Constant (single value): Element-by-Element, apply the math operation over every element in the array\n",
    ">```python\n",
    "a=np.array([0,1,2,3])\n",
    "a+1\n",
    "a-1\n",
    "a*2\n",
    "a/2\n",
    "np.power(a,2)\n",
    "np.log10(a)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_1.png\" width=\"400\">\n",
    "\n",
    "- Array and Array: \n",
    "    - Identical Shapes: √\n",
    "    - Different shapes: You need to make sure one axis of <font color=\"blue\">operator</font> is of length 1 and the other axises are of same sizes as the <font color=\"red\">operand</font>. For example: a.shape = (123,3), b.shape = (1,3)\n",
    ">```python\n",
    "a=np.array([[0,1,2,3],[4,5,6,7]])\n",
    "b=np.array([1,2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[0,1,2,3],[4,5,6,7]])\n",
    "b=np.array([[1],[2]])\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([1,2])\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error, because of unmatched dimensionalities between operator and operand\n",
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error solved by using .reshape() method to transform dimensions\n",
    "b=np.array([1,2])\n",
    "b=b.reshape(2,1)\n",
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([1,2])\n",
    "a-b[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance vector between all observations and the first centroid\n",
    "data-random_centroids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the distance between all data and first centroid\n",
    "#axis: the axis to be diminished\n",
    "#(150,4) -> (150,1)\n",
    "np.linalg.norm(data-random_centroids[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get distance between all data poitns and all centroids\n",
    "distances=np.linalg.norm(data[:,None]-random_centroids,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[:,None]-random_centroids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3. Pairwise Distance of digit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array comparison\n",
    "- Return value\n",
    "    - np.min, np.max, np.sort\n",
    "- Return index, `+arg`\n",
    "    - np.argmin, np.argmax, np.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([2,7,0,1,3,4,5,6,7,8,9,10])\n",
    "print('The smallest value is:', np.min(a))\n",
    "print('The index of the smallest value is:',np.argmin(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The index of values<2', np.where(a<2))\n",
    "print('The index of values=7', np.where(a==7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which point is closest to the FIRST centroid?\n",
    "np.linalg.norm(data-random_centroids[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which centroid is closest to the FIRST observation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the index of the centroid closest to EACH observation\n",
    "# (150,3) -> (150,1)\n",
    "np.argmin(distances,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the distance between each data point and each centroid\n",
    "#Assign point to the cluster depending on this distance\n",
    "def group_assignment(data,centroids):\n",
    "    distances=np.linalg.norm(data[:,None]-centroids,axis=2) #shape (150,3)\n",
    "    assignments=np.argmin(distances, axis=1)\n",
    "    return(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run_cluster=group_assignment(data,random_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run_cluster #first point belongs to this cluster after first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4. Update the centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Centroids: centers of a group of points/vectors\n",
    "    - Measure: mean of coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop/img/centroids.png\" width=\"250px\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a: four observations, 3 dimensions\n",
    "#(4,3) -> (1,3)\n",
    "a=[[1,2,3],\n",
    "   [2,3,4],\n",
    "   [4,5,6],\n",
    "   [6,7,8]]\n",
    "centroids="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group0=data[first_run_cluster==0,:]\n",
    "updated_centroid0="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centroids(data,clusters):\n",
    "    centroids=np.empty((0,4))\n",
    "    for i in np.unique(clusters):\n",
    "        group=data[clusters==i,:]\n",
    "        centroid=np.mean(group,axis=0)\n",
    "        centroids=np.vstack([centroids,centroid])\n",
    "    return(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_centroids(data,first_run_cluster) #get our second-run centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_centroids=update_centroids(data,first_run_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5. Calculate the Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss in Machine Learning = Goodness-of-fit\n",
    "- Types of loss: L1 (abs error), L2 (sqaured error) and logistic/cross-entropy\n",
    "    - L1: mean(abs(y-ŷ))\n",
    "    - L2: mean((y-ŷ)^2)\n",
    "    - Log: mean(-sum(y*log(ŷ))\n",
    "- For KMeans, we use L2 loss:\n",
    "    - average squared distance between points and their centroids\n",
    "    - formula: mean((y-centroid)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get the distances between points in Group 0 and the first centroid\n",
    "np.linalg.norm(data[first_run_cluster==0,:]-new_centroids[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(data,clusters,centroids):\n",
    "    ls=0\n",
    "    for i in np.unique(clusters):\n",
    "        ls+=np.sum(np.power(np.linalg.norm(data[clusters==i,:]-centroids[i],axis=1),2)) #distance\n",
    "    ls=ls/len(data) #squared distance\n",
    "    return(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance of first run\n",
    "loss(data,first_run_cluster,new_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for specific times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the algorithm 15 times\n",
    "centroids=random_centroids\n",
    "losses=[]\n",
    "for run in range(15):\n",
    "    clusters=group_assignment(data,centroids)\n",
    "    centroids=update_centroids(data,clusters)\n",
    "    current_loss=loss(data,clusters,centroids)\n",
    "    print(run,current_loss)\n",
    "    losses.append(current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbow method of finding the optimal number of iteration\n",
    "trace=go.Scatter(\n",
    "    x=list(range(len(losses))),\n",
    "    y=losses,\n",
    "    mode='lines'\n",
    ")\n",
    "go.Figure(trace).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=random_centroids\n",
    "current_loss=0.6\n",
    "losses=[]\n",
    "run=0\n",
    "while current_loss>0.6:\n",
    "    clusters=group_assignment(data,centroids)\n",
    "    centroids=update_centroids(data,clusters)\n",
    "    current_loss=loss(data,clusters,centroids)\n",
    "    print(run,current_loss)\n",
    "    losses.append(current_loss)\n",
    "    run+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training until group assignments do not change anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=random_centroids\n",
    "old_clusters=np.array([1])\n",
    "clusters=np.array([0])\n",
    "losses=[]\n",
    "run=0\n",
    "while sum(old_clusters-clusters)!=0:\n",
    "    old_clusters=clusters\n",
    "    clusters=group_assignment(data,centroids)\n",
    "    centroids=update_centroids(data,clusters)\n",
    "    current_loss=loss(data,clusters,centroids)\n",
    "    print(run,current_loss)\n",
    "    losses.append(current_loss)\n",
    "    run+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an integrated function of KMeans (stop training when groups converge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(K,data):\n",
    "    centroid_index=np.random.choice(len(data),K,False)\n",
    "    centroids=data[centroid_index,:]\n",
    "    old_clusters=np.array([1])\n",
    "    clusters=np.array([0])\n",
    "    losses=[]\n",
    "    run=0\n",
    "    while sum(old_clusters-clusters)!=0:\n",
    "        old_clusters=clusters\n",
    "        clusters=group_assignment(data,centroids)\n",
    "        centroids=update_centroids(data,clusters)\n",
    "        current_loss=loss(data,clusters,centroids)\n",
    "        print('Run',run,'| Loss:',current_loss)\n",
    "        losses.append(current_loss)\n",
    "        run+=1\n",
    "    return(clusters,centroids,current_loss,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters,centroids,_,_=KMeans(3,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans++: An Improvement of KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- New way of initialization\n",
    "    - STEP 1: Random pick one centroid from the points\n",
    "    - STEP 2: Calculate the distance _D(k)_ between points and their nearest centroid\n",
    "    - STEP 3: Pick one more centroid with probability proportional to _D(k)_\n",
    "    - STEP 4: Repeat STEP 2 and STEP 3 until the number of centroids reaching the required value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHORTCUT: sklearn function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "documentation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=3,init='random',max_iter=20)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(targets,clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best value of K: Elbow Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a data set about development score of countries\n",
    "countries=pd.read_csv('https://juniorworld.github.io/python-workshop/doc/country-index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=5)\n",
    "kmeans.fit(countries.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['countries'][kmeans.labels_==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_list=[]\n",
    "for i in range(1,21):\n",
    "    kmeans=KMeans(n_clusters=i,init='k-means++')\n",
    "    kmeans.fit(countries.iloc[:,3:])\n",
    "    ls=loss(np.array(countries.iloc[:,3:]),kmeans.labels_,kmeans.cluster_centers_)\n",
    "    ls_list.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#elbow method of finding the optimal K\n",
    "trace=go.Scatter(\n",
    "    x=list(range(1,21)),\n",
    "    y=ls_list,\n",
    "    mode='lines'\n",
    ")\n",
    "go.Figure(trace).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning: K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)\n",
    "- Distance-based Spatial Voting Model\n",
    "- Purpose: Classify a new point according its nearest neighbors\n",
    "- Input: a set of data with labels\n",
    "- Output: K nearest neighbors of N unlabeled data\n",
    "    - Assign the category according K's labels\n",
    "- Parameter: K\n",
    "\n",
    "<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2018/08/Value-of-K.gif\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Movie|#Fight scenes|#Kiss scenes|Genre|\n",
    "|-----|:-----------:|:----------:|:---:|\n",
    "|California Man|3|104|Love|\n",
    "|He's not that into you|2|100|Love|\n",
    "|Beautiful Woman|1|81|Love|\n",
    "|Kevin Longblade|101|10|Action|\n",
    "|Robo Slayer 3000|99|5|Action|\n",
    "|Amped II|98|2|Action|\n",
    "|<font style='color:blue'>XXXXX</font>|<font style='color:blue'>18</font>|<font style='color:blue'>90</font>|<font style='color:red'>?</font>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
