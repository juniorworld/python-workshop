{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/portfolio/week9.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a model to give predictions only based on input data\n",
    "- Dimension Reduction: PCA or SVD\n",
    "- Clustering Analysis: Modularity, KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA: Principal Component Analysis\n",
    "- Purpose: Dimension Reduction + Visualization\n",
    "- Input: high-dimensional data\n",
    "- Output: low-dimensional data\n",
    "- Survey: 100 items -> 5 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3) #initialize a PCA decomposer\n",
    "pca.fit(data) #train this decomposer with current data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_pca=pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_pca[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot this matrix\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.sign_in('USER NAME','API TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace=go.Scatter3d(\n",
    "                 x=iris_pca[:,0],\n",
    "                 y=iris_pca[:,1],\n",
    "                 z=iris_pca[:,2],\n",
    "                 mode='markers',\n",
    "                 marker={'size':3,'color':iris.target})\n",
    "py.iplot([trace],filename='iris pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace=go.Scatter(\n",
    "                 x=iris_pca[:,0],\n",
    "                 y=iris_pca[:,1],\n",
    "                 mode='markers',\n",
    "                 marker={'size':3,'color':iris.target})\n",
    "py.iplot([trace],filename='iris pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another data set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "#load digits data\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits is composed of three lists: image list, data list, and label list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"images\" contains 8x8 images of each data point.\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"target\" contains a list of results\n",
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"data\" contains brighness numbers of each data point\n",
    "data=digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape #overall 1797 cases * 64 brightness number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0,:] #first case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the minimum number of components which can explain over 80% of data variance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3) #specify the component number to 3\n",
    "pca.fit(data)\n",
    "digits_3d=pca.transform(data) #obtain the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace=go.Scatter3d(\n",
    "        x=digits_3d[:,0],\n",
    "        y=digits_3d[:,1],\n",
    "        z=digits_3d[:,2],\n",
    "        mode='markers',\n",
    "        marker={'size':2,'color':digits.target,'colorscale':'Rainbow'},\n",
    "        text=digits.target)\n",
    "py.iplot([trace],filename='digits space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace=go.Scatter(\n",
    "        x=digits_3d[:,0],\n",
    "        y=digits_3d[:,1],\n",
    "        mode='markers',\n",
    "        marker={'size':2,'color':digits.target,'colorscale':'Rainbow'},\n",
    "        text=digits.target)\n",
    "py.iplot([trace],filename='digits space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Break\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "- Purpose: cluster data points according to their euclidean distance\n",
    "- Input: observation data\n",
    "- Output: predicted groups\n",
    "- Procedure:\n",
    "    - STEP 1. Intialize K cluster centroids\n",
    "    - STEP 2. Calculate the distance between each data point and each centroid\n",
    "    - STEP 3. Assign data point to the cluster whose centroid is closest to it\n",
    "    - STEP 4. Update the cluster centroids with new group\n",
    "    - STEP 5. Repeat STEP 1~4 for specific time or until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: red\">1. Step-by-Step Breakdowns</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1. Initialize K cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly pick K points as centroids\n",
    "#Suppose: K=10\n",
    "random_centroids_index=np.random.choice(range(data.shape[0]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_centroids=data[random_centroids_index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2. Calculate the pairwise distance between data point and each centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) VECTOR NORM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/vector_norm.png\" width=\"200px\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to Pythagorean theorem, if U=(U1,U2,U3,...,Un), ‖U‖=sqrt(U1^2 + U2^2 + U3^2 +...+ Un^2)\n",
    "a=np.array([0,1,2,3])\n",
    "norm="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHORTCUT: Use np.linalg.norm() to calculate the vector norm\n",
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) VECTOR SUBTRACTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/vector_minus.png\" width=\"250px\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([0,1])\n",
    "b=np.array([0,2])\n",
    "np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the pairwise distance between first data point and first cluster's centroid\n",
    "np.linalg.norm(data[0]-random_centroids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the distance between all data and first centroid in one line\n",
    "np.linalg.norm(data-random_centroids[0],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3. Pairwise Distance of digit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the distance between each data point and each centroid, assign point to the cluster depending on this distance\n",
    "#You need to get a list of cluster assignment\n",
    "#HINT: you can use np.argmin() to find the index of minimum value\n",
    "#----------------------------------\n",
    "def single_run_KMeans(data,centroids):\n",
    "    clusters=[] #initialization\n",
    "    \n",
    "    \n",
    "    #Write your code here\n",
    "    clusters=np.array(clusters)\n",
    "    return(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run_cluster=single_run_KMeans(data,random_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run_cluster[0] #first point belongs to this cluster after first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4. Update the centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centroids: centers of a group of points/vectors\n",
    "    - Measure: avarage of coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/centroids.png\" width=\"250px\" align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2,3],\n",
    "   [2,3,4],\n",
    "   [4,5,6],\n",
    "   [6,7,8]]\n",
    "print(np.mean(a,axis=0)) #column sum\n",
    "print(np.mean(a,axis=1)) #row sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the centroids of clusters\n",
    "def update_centroids(data,clusters):\n",
    "    centroids=np.array([])\n",
    "    for i in range(10):\n",
    "        \n",
    "        #Write your code here\n",
    "    \n",
    "    return(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[first_run_cluster==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_centroids(data,first_run_cluster) #get our second-run centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5. Calculate the Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss in Machine Learning = Goodness-of-fit in Social Sciences\n",
    "- Types of loss: L1 (abs error), L2 (sqaured error) and logistic/cross-entropy\n",
    "    - L1: mean(abs(y-ŷ))\n",
    "    - L2: mean((y-ŷ)^2)\n",
    "    - Log: mean(-sum(y*log(ŷ))\n",
    "- For KMeans, we use L2 loss:\n",
    "    - average squared distance between points and their centroids\n",
    "    - formula: mean((y-centroid)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(data,centroids):\n",
    "    ls=[]\n",
    "    \n",
    "    #WRITE YOUR CODE HERE\n",
    "        \n",
    "    return(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance of first run\n",
    "loss(data,first_run_cluster,random_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model for specific times (integrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=random_centroids\n",
    "loss_list=[]\n",
    "for run in range(20):\n",
    "    clusters=single_run_KMeans(data,centroids)\n",
    "    current_loss=loss(data,clusters,centroids)\n",
    "    print(run,current_loss)\n",
    "    loss_list.append(current_loss)\n",
    "    centroids=update_centroids(data,clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbow method of finding the optimal number of iteration\n",
    "trace=go.Scatter(\n",
    "    x=list(range(20)),\n",
    "    y=loss_list,\n",
    "    mode='lines'\n",
    ")\n",
    "py.iplot([trace],filename='learning curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a look at the cluster results\n",
    "digits.target[clusters==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model until convergence (integrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=random_centroids\n",
    "current_loss=10000\n",
    "loss_list=[]\n",
    "while current_loss>700:\n",
    "    clusters=single_run_KMeans(data,centroids)\n",
    "    current_loss=loss(data,clusters,centroids)\n",
    "    print(current_loss)\n",
    "    loss_list.append(current_loss)\n",
    "    centroids=update_centroids(data,clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans++: An Improvement of KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- New way of initialization\n",
    "    - STEP 1: Random pick one centroid from the points\n",
    "    - STEP 2: Calculate the distance _D(k)_ between points and their nearest centroid\n",
    "    - STEP 3: Pick one more centroid with probability proportional to _D(k)_\n",
    "    - STEP 4: Repeat STEP 2 and STEP 3 until the number of centroids reaching the required value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1\n",
    "first_centroid_index=np.random.choice(range(data.shape[0]),1)\n",
    "first_centroid=data[first_centroid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HINT 1: You can use np.random.choice(data,1,p=[probability list]) to pick one point randomly with given list of probability\n",
    "#HINT 2: You can use np.vstack((array1,array2)) to add new row\n",
    "#WRITE YOUR CODE HERE\n",
    "centroids=first_centroid\n",
    "for i in range(9):\n",
    "    \n",
    "\n",
    "    centroids.append(next_centroid)\n",
    "centroids=np.array(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids=first_centroid\n",
    "for i in range(9):\n",
    "    distances=[]\n",
    "    for j in data:\n",
    "        dist=np.min(np.linalg.norm(j-centroids))\n",
    "        distances.append(dist)\n",
    "    distances=np.array(distances)/sum(distances)\n",
    "    next_centroid_index=np.random.choice(range(data.shape[0]),1,p=distances)\n",
    "    next_centroid=data[next_centroid_index]\n",
    "    centroids=np.vstack((centroids,next_centroid))\n",
    "centroids=np.array(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine everything into a giant function\n",
    "- input: data\n",
    "- parameter:init = random/kmeans++, iteration = num/covergence threshold\n",
    "- output: a list of cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(data,init='random',iteration=10):\n",
    "\n",
    "\n",
    "\n",
    "    return(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY Kmeans() to iris data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHORTCUT: sklearn function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "documentation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=10,init='k-means++',max_iter=20)\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target[kmeans.labels_==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a data set about development score of countries\n",
    "countries=pd.read_csv('https://juniorworld.github.io/python-workshop-2018/doc/country-index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=5,init='k-means++')\n",
    "kmeans.fit(countries.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['countries'][kmeans.labels_==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_list=[]\n",
    "for i in range(1,21):\n",
    "    kmeans=KMeans(n_clusters=i,init='k-means++')\n",
    "    kmeans.fit(countries.iloc[:,3:])\n",
    "    ls=loss(np.array(countries.iloc[:,3:]),kmeans.labels_,kmeans.cluster_centers_)\n",
    "    ls_list.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elbow method of finding the optimal K\n",
    "trace=go.Scatter(\n",
    "    x=list(range(1,21)),\n",
    "    y=ls_list,\n",
    "    mode='lines'\n",
    ")\n",
    "py.iplot([trace],filename='learning curve')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
