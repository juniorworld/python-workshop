{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/portfolio/week7.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/data%20collection.png\" width=\"400px\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/NLP_.png\" width=\"700px\" height=\"400px\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate how to go through these five steps for English and Chinese texts respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "- Main task: convert the case, remove punctuations and special characters like hashtags, hyperlinks\n",
    "- Use Regular Expression for Pattern Matching\n",
    "- Convert the case: `.lower()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression Cheat Sheet\n",
    "- `.` matches any single character\n",
    "- `[...]` group matching, matches any one of the characters inside the square brackets\n",
    "- `[^x]` matches one character that is not x\n",
    "- `|` an “or” operator, matches patterns on either side of the |.\n",
    "- `*` matches at least 0 times.\n",
    "- `+` matches at least 1 times.\n",
    "- `?` matches at most 1 times.\n",
    "- `{n}` matches n times\n",
    "- `(...)` grouping in regular expressions\n",
    "- `\\\\N` – backreference to group N\n",
    "- `^` matches the start of the string.\n",
    "- `$` matches the end of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">1a. English</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install regular expression package for pattern matching\n",
    "! pip3 install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sub() function to match pattern and substitute the matched words with new pattern\n",
    "a='I only have 100 dollars in my pocket. What I can buy?'\n",
    "re.sub('I','You',a) #substitute a word with another word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substitute a word with nothing, meaning removing the word\n",
    "re.sub('I','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match a group of words by using []. \"a-z\" means all capital letters.\n",
    "re.sub('[A-Z]','*',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all letters in lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hide the numbers\n",
    "re.sub('[0-9]','*',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all alphanumeric characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all charaters that are not alphanumeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shortcut to remove all punctuation\n",
    "re.sub('\\p{P}+',' ',a) #\\p stands for POSIX characters. {P} stands for punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hashtags\n",
    "a='''@JerryNadler admits on #CNN they have no proof of Obstruction by @realDonaldTrump it's just his \"personal opinion\" Meet the new #WitchHunt Same as the old #WitchHunt cc @DonaldJTrumpJr'''\n",
    "re.sub('#[^ ]+','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract hashtags by findall() function\n",
    "re.findall('#[^ ]+',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all mentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hyperlinks\n",
    "a='Tesla’s abrupt shift to online-only car sales, after racing to open stores, battered its share price and raised questions about its future. https://goo.gl/rwGHTP'\n",
    "re.sub('https://[^ ]+|http://[^ ]+','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform all letters to lower case\n",
    "a.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data_cleaning() function to convert letter case, remove punctuations, numbers, mentions, hashtags and hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text){\n",
    "    \n",
    "    #Write your code here\n",
    "    \n",
    "    return(text)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test your function with a post from @realDonaldTrump\n",
    "a='@seanhannity “We the people will now be subjected to the biggest display of modern day McCarthyism....which is the widest fishing net expedition....every aspect of the presidents life....all in order to get power back so they can institute Socialism.” https://t.co/izb2tTrINB'\n",
    "data_cleaning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Break\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "- Definition: tokenization is a process of splitting sentences/paragraphs/documents into a set of words.\n",
    "- Differences in Languages:\n",
    "    - English: **words** are naturally separated with spaces\n",
    "    - Korean: **phrases** are naturally separated with spaces\n",
    "        - konlpy (http://konlpy.org/)\n",
    "    - Chinese/Japanese: **no spaces** in text\n",
    "        - Chinese: jieba (https://github.com/fxsjy/jieba)\n",
    "        - Japanese: jNlp (https://github.com/kevincobain2000/jProcessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize English Text: Hunt for Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the following sentence into words\n",
    "sentence='Mr. Zuckerberg, who runs Facebook, Instagram, WhatsApp and Messenger, on Wednesday expressed his intentions to change the essential nature of social media. Instead of encouraging public posts, he said he would focus on private and encrypted communications, in which users message mostly smaller groups of people they know. Unlike publicly shared posts that are kept as users’ permanent records, the communications could also be deleted after a certain period of time.'\n",
    "sentence=data_cleaning(sentence)\n",
    "words="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(words).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    **<b>Extra Knowledge</b>** We can use funtion <font style='color:red;font-weight:bold;'>gensim.parsing.preprocessing.stem_text(text)</font> to stem words in the sentence.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Chinese Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a package package \"jieba\" to tokenize Chinese text.<br>\n",
    "<br>\n",
    "**Why jieba?**\n",
    "- It adopts a hybrid method combining both statistical/probabilistic inference and pattern matching based on dictionary. \n",
    "    - capable to recognize words existing in the pre-defined dictionary\n",
    "    - capable to find new words.\n",
    "- Two dictionaries:\n",
    "    - System dictionary\n",
    "        - Simplied Chinese\n",
    "        - Simplied+Traditional Chinese\n",
    "    - User dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(jieba.cut('你好，这是一个简单的句子。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it can segment tradional Chinese text by using statistical inference method.\n",
    "list(jieba.cut('你好，這是一個簡單的句子。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#however, statistical inference is not perfect.\n",
    "list(jieba.cut('談判擱置，工會號召靜坐。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(jieba.cut('谈判搁置，工会号召静坐。'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurate Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better segment traditional Chinese text, we need to upgrade system dictionary to include traditional Chinese words.<br>\n",
    "Download the system dictionary from this link:https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load another dictionary to support traditional Chinese\n",
    "jieba.set_dictionary('PATH OF DICTIONARY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try tokenizing this sentence again\n",
    "list(jieba.cut('談判擱置，工會號召靜坐。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some names and special terminologies cannot be properly identified.\n",
    "print(list(jieba.cut('中央上周二向特首林鄭月娥發公函'))) #very long name\n",
    "print(list(jieba.cut('台灣蔡英文總統日前表示希望與日本舉行安保對話'))) #names including frequently used words\n",
    "print(list(jieba.cut('高雄市長韓國瑜本月稍後訪問港澳深圳廈門四市'))) #names including frequently used words\n",
    "print(list(jieba.cut('汶萊的全稱為汶萊達魯薩蘭國。'))) #special terminologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build your user dictionary (time-consuming)\n",
    "file=open('user_dict.txt','w',encoding='utf-8')\n",
    "file.write('林鄭月娥\\n')\n",
    "file.write('蔡英文\\n')\n",
    "file.write('韓國瑜\\n')\n",
    "file.write('汶萊達魯薩蘭國\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your user dictionary\n",
    "jieba.load_userdict('user_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After loading user dictionary:\n",
    "print(list(jieba.cut('中央上周二向特首林鄭月娥發公函'))) #very long name\n",
    "print(list(jieba.cut('台灣蔡英文總統日前表示希望與日本舉行安保對話'))) #names including frequently used words\n",
    "print(list(jieba.cut('高雄市長韓國瑜本月稍後訪問港澳深圳廈門四市'))) #names including frequently used words\n",
    "print(list(jieba.cut('请问：根據碳碳键键能能否否定定律一'))) #special terminologies\n",
    "print(list(jieba.cut('汶萊的全稱為汶萊達魯薩蘭國。'))) #terminologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words\n",
    "Stop words are useless for understanding text.<br>\n",
    "In English: at, in, on, for, of, a, an, the...<br>\n",
    "In Chinese: 的，地，得，了.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the combination of 不得了 (holy great) is not a stop word which is used to convey extreme compliment over something.<br>\n",
    "√ Absolute Match. × Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'a' in ['a','b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'a' in ['aa','b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'a' not in ['aa','b','c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chinese stop words file: https://juniorworld.github.io/python-workshop-2018/doc/stop_words_chi.txt<br>\n",
    "Chinese stop words file: https://juniorworld.github.io/python-workshop-2018/doc/stop_words_eng.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_chi=open('FILE PATH','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_chi=[]\n",
    "for line in file_chi.readlines():\n",
    "    line=line.strip() #remove line break\n",
    "    stop_words_chi.append(line) #update the list of stop words line by line\n",
    "file_chi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_words_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eng=open('FILE PATH','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_eng=[]\n",
    "for line in file_eng.readlines():\n",
    "    line=line.strip() #remove line break\n",
    "    stop_words_eng.append(line) #update the list of stop words line by line\n",
    "file_eng.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stop_words_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Match of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='Facebook将向加密通信转型，打造以隐私为中心的平台。'\n",
    "words=list(jieba.cut(sentence))\n",
    "words_new=[]\n",
    "for word in words:\n",
    "    if word not in stop_words_chi:\n",
    "        words_new.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop in the list\n",
    "a=[1,2,3,4,5]\n",
    "b=             #increase element by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop and if statement in the list\n",
    "a=[1,2,3,4,5]\n",
    "b=[i for i in a if i<4]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new=[word for word in list(jieba.cut(sentence)) if word not in stop_words_chi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean and tokenize this sentence and remove the stop words\n",
    "sentence='Mr. Zuckerberg, who runs Facebook, Instagram, WhatsApp and Messenger, on Wednesday expressed his intentions to change the essential nature of social media. Instead of encouraging public posts, he said he would focus on private and encrypted communications, in which users message mostly smaller groups of people they know. Unlike publicly shared posts that are kept as users’ permanent records, the communications could also be deleted after a certain period of time.'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 10 fade-in and fade-out words in speeches.<br>\n",
    "The magnitude of difference is measured by the change in their relative frequencies:<br>\n",
    "<p style='text-align:center;font-size:15px;'>Relative Freq (RF) = word frequency / max word frequency</p>\n",
    "<p style='text-align:center;font-size:15px;'>Difference = RF<font size='2px'>2019</font> - RF<font size='2px'>2009</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:<br>\n",
    "- Chinese: Annual government work reports, <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2019_Government_Work_Report.txt\">2019</a> vs <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2009_Government_Work_Report.txt\">2009</a>\n",
    "- English: State of the Union address, <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2019_SoU.txt\">2019</a> vs <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2009_SoU.txt\">2009</a><br>\n",
    "\n",
    "*Hint:*<br>\n",
    "*1. You can use `pd.concat([df1,df2],axis=1)` to combine two data frames by columns*<br>\n",
    "*2. You can use `df.fillna(0)` to replace NAN value with 0.*<br>\n",
    "*3. You can use `df.sort_values(column_name)` to sort a certain column.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2019=open('FILE PATH','r',encoding='utf-8')\n",
    "file_2009=open('FILE PATH','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Your Code Here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
