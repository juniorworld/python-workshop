{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/portfolio/week7.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/data%20collection.png\" width=\"400px\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/NLP_.png\" width=\"700px\" height=\"400px\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate how to go through these five steps for English and Chinese texts respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "- Main task: convert the case, remove punctuations and special characters like hashtags, hyperlinks\n",
    "- Use Regular Expression for Pattern Matching\n",
    "- Convert the case: `.lower()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression Cheat Sheet\n",
    "- `.` matches any single character\n",
    "- `[...]` group matching, matches any one of the characters inside the square brackets\n",
    "- `[^x]` matches one character that is not x\n",
    "- `|` an “or” operator, matches patterns on either side of the |.\n",
    "- `*` matches at least 0 times.\n",
    "- `+` matches at least 1 times.\n",
    "- `?` matches at most 1 times.\n",
    "- `{n}` matches n times\n",
    "- `(...)` grouping in regular expressions\n",
    "- `\\\\N` – backreference to group N\n",
    "- `^` matches the start of the string.\n",
    "- `$` matches the end of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">1a. English</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in c:\\users\\yuner\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#install regular expression package for pattern matching\n",
    "! pip3 install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You only have 100 dollars in my pocket. What You can buy?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use sub() function to match pattern and substitute the matched words with new pattern\n",
    "a='I only have 100 dollars in my pocket. What I can buy?'\n",
    "re.sub('I','You',a) #substitute a word with another word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' only have 100 dollars in my pocket. What  can buy?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Substitute a word with nothing, meaning removing the word\n",
    "re.sub('I','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* only have 100 dollars in my pocket. *hat * can buy?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Match a group of words by using []. \"a-z\" means all capital letters.\n",
    "re.sub('[A-Z]','*',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I   100    . W I  ?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all letters in lower case\n",
    "re.sub('[a-z]','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I only have *** dollars in my pocket. What I can buy?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hide the numbers\n",
    "re.sub('[0-9]','*',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'       .    ?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all alphanumeric characters\n",
    "re.sub('[0-9a-zA-Z]','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I only have 100 dollars in my pocket  What I can buy '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all charaters that are not alphanumeric\n",
    "re.sub('[^0-9a-zA-Z]',' ',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I only have 100 dollars in my pocket  What I can buy '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shortcut to remove all punctuation\n",
    "re.sub('\\p{P}+',' ',a) #\\p stands for POSIX characters. {P} stands for punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@JerryNadler admits on  they have no proof of Obstruction by @realDonaldTrump it\\'s just his \"personal opinion\" Meet the new  Same as the old  cc @DonaldJTrumpJr'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove hashtags\n",
    "a='''@JerryNadler admits on #CNN they have no proof of Obstruction by @realDonaldTrump it's just his \"personal opinion\" Meet the new #WitchHunt Same as the old #WitchHunt cc @DonaldJTrumpJr'''\n",
    "re.sub('#[^ ]+','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#CNN', '#WitchHunt', '#WitchHunt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract hashtags by findall() function\n",
    "re.findall('#[^ ]+',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@JerryNadler', '@realDonaldTrump', '@DonaldJTrumpJr']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract all mentions\n",
    "re.findall('@[^ ]+',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla’s abrupt shift to online-only car sales, after racing to open stores, battered its share price and raised questions about its future. '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove hyperlinks\n",
    "a='Tesla’s abrupt shift to online-only car sales, after racing to open stores, battered its share price and raised questions about its future. https://goo.gl/rwGHTP'\n",
    "re.sub('https://[^ ]+|http://[^ ]+','',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tesla’s abrupt shift to online-only car sales, after racing to open stores, battered its share price and raised questions about its future. https://goo.gl/rwghtp'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tranform all letters to lower case\n",
    "a.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data_cleaning() function to convert letter case, remove punctuations, numbers, mentions, hashtags and hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[0-9]+','',text)\n",
    "    text=re.sub('@[^ ]+','',text)\n",
    "    text=re.sub('#[^ ]+','',text)\n",
    "    text=re.sub('http://[^ ]+|https://[^ ]+','',text)\n",
    "    text=re.sub('\\p{P}+',' ',text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  we the people will now be subjected to the biggest display of modern day mccarthyism which is the widest fishing net expedition every aspect of the presidents life all in order to get power back so they can institute socialism  '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test your function with a post from @realDonaldTrump\n",
    "a='@seanhannity “We the people will now be subjected to the biggest display of modern day McCarthyism....which is the widest fishing net expedition....every aspect of the presidents life....all in order to get power back so they can institute Socialism.” https://t.co/izb2tTrINB'\n",
    "data_cleaning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  We the people will now be subjected to the biggest display of modern day McCarthyism which is the widest fishing net expedition every aspect of the presidents life all in order to get power back so they can institute Socialism  '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\p{P}+',' ',re.sub('http://[^ ]+|https://[^ ]+|@[^ ]+|#[^ ]+','',a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Break\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "- Definition: tokenization is a process of splitting sentences/paragraphs/documents into a set of words.\n",
    "- Differences in Languages:\n",
    "    - English: **words** are naturally separated with spaces\n",
    "    - Korean: **phrases** are naturally separated with spaces\n",
    "        - konlpy (http://konlpy.org/)\n",
    "    - Chinese/Japanese: **no spaces** in text\n",
    "        - Chinese: jieba (https://github.com/fxsjy/jieba)\n",
    "        - Japanese: jNlp (https://github.com/kevincobain2000/jProcessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize English Text: Hunt for Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the following sentence into words\n",
    "sentence='Mr. Zuckerberg, who runs Facebook, Instagram, WhatsApp and Messenger, on Wednesday expressed his intentions to change the essential nature of social media. Instead of encouraging public posts, he said he would focus on private and encrypted communications, in which users message mostly smaller groups of people they know. Unlike publicly shared posts that are kept as users’ permanent records, the communications could also be deleted after a certain period of time.'\n",
    "sentence=data_cleaning(sentence)\n",
    "words=sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    **<b>Extra Knowledge</b>** We can use funtion <font style='color:red;font-weight:bold;'>gensim.parsing.preprocessing.stem_text(text)</font> to stem words in the sentence.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Chinese Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a package package \"jieba\" to tokenize Chinese text.<br>\n",
    "<br>\n",
    "**Why jieba?**\n",
    "- It adopts a hybrid method combining both statistical/probabilistic inference and pattern matching based on dictionary. \n",
    "    - capable to recognize words existing in the pre-defined dictionary\n",
    "    - capable to find new words.\n",
    "- Two dictionaries:\n",
    "    - System dictionary\n",
    "        - Simplied Chinese\n",
    "        - Simplied+Traditional Chinese\n",
    "    - User dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\users\\yuner\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip3 install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\yuner\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.716 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['你好', '，', '这是', '一个', '简单', '的', '句子', '。']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(jieba.cut('你好，这是一个简单的句子。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你好', '，', '這是', '一個', '簡單', '的', '句子', '。']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it can segment tradional Chinese text by using statistical inference method.\n",
    "list(jieba.cut('你好，這是一個簡單的句子。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['談判', '擱置', '，', '工會號', '召靜', '坐', '。']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#however, statistical inference is not perfect.\n",
    "list(jieba.cut('談判擱置，工會號召靜坐。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['谈判', '搁置', '，', '工会', '号召', '静坐', '。']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(jieba.cut('谈判搁置，工会号召静坐。'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurate Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better segment traditional Chinese text, we need to upgrade system dictionary to include traditional Chinese words.<br>\n",
    "Download the system dictionary from this link:https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load another dictionary to support traditional Chinese\n",
    "jieba.set_dictionary('C:\\\\Users\\\\yuner\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Lib\\\\site-packages\\\\jieba\\\\dict.txt.big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\yuner\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\site-packages\\jieba\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\yuner\\AppData\\Local\\Temp\\jieba.u425828d27b9dbcd864ed100138e410f6.cache\n",
      "Loading model cost 1.489 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['談判', '擱置', '，', '工會', '號召', '靜坐', '。']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try tokenizing this sentence again\n",
    "list(jieba.cut('談判擱置，工會號召靜坐。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['中央', '上周二', '向', '特首', '林', '鄭月', '娥', '發', '公函']\n",
      "['台灣', '蔡', '英文', '總統', '日前', '表示', '希望', '與', '日本', '舉行', '安保', '對話']\n",
      "['高雄', '市長', '韓國', '瑜', '本月', '稍後', '訪問', '港澳', '深圳', '廈門', '四市']\n",
      "['汶萊', '的', '全稱', '為汶萊', '達魯', '薩蘭國', '。']\n"
     ]
    }
   ],
   "source": [
    "#Some names and special terminologies cannot be properly identified.\n",
    "print(list(jieba.cut('中央上周二向特首林鄭月娥發公函'))) #very long name\n",
    "print(list(jieba.cut('台灣蔡英文總統日前表示希望與日本舉行安保對話'))) #names including frequently used words\n",
    "print(list(jieba.cut('高雄市長韓國瑜本月稍後訪問港澳深圳廈門四市'))) #names including frequently used words\n",
    "print(list(jieba.cut('汶萊的全稱為汶萊達魯薩蘭國。'))) #special terminologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build your user dictionary (time-consuming)\n",
    "file=open('user_dict.txt','w',encoding='utf-8')\n",
    "file.write('林鄭月娥\\n')\n",
    "file.write('蔡英文\\n')\n",
    "file.write('韓國瑜\\n')\n",
    "file.write('汶萊達魯薩蘭國\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your user dictionary\n",
    "jieba.load_userdict('user_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['中央', '上周二', '向', '特首', '林鄭月娥', '發', '公函']\n",
      "['台灣', '蔡英文', '總統', '日前', '表示', '希望', '與', '日本', '舉行', '安保', '對話']\n",
      "['高雄', '市長', '韓國瑜', '本月', '稍後', '訪問', '港澳', '深圳', '廈門', '四市']\n",
      "['汶萊', '的', '全稱', '為', '汶萊達魯薩蘭國', '。']\n"
     ]
    }
   ],
   "source": [
    "#After loading user dictionary:\n",
    "print(list(jieba.cut('中央上周二向特首林鄭月娥發公函'))) #very long name\n",
    "print(list(jieba.cut('台灣蔡英文總統日前表示希望與日本舉行安保對話'))) #names including frequently used words\n",
    "print(list(jieba.cut('高雄市長韓國瑜本月稍後訪問港澳深圳廈門四市'))) #names including frequently used words\n",
    "print(list(jieba.cut('汶萊的全稱為汶萊達魯薩蘭國。'))) #terminologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words\n",
    "Stop words are useless for understanding text.<br>\n",
    "In English: at, in, on, for, of, a, an, the...<br>\n",
    "In Chinese: 的，地，得，了.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the combination of 不得了 (holy great) is not a stop word which is used to convey extreme compliment over something.<br>\n",
    "√ Absolute Match. × Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in ['a','b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in ['aa','b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' not in ['aa','b','c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chinese stop words file: https://juniorworld.github.io/python-workshop-2018/doc/stop_words_chi.txt<br>\n",
    "English stop words file: https://juniorworld.github.io/python-workshop-2018/doc/stop_words_eng.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_chi=open('C:\\\\Users\\\\yuner\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Lib\\\\site-packages\\\\jieba\\\\stop_words_chi.txt','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_chi=[]\n",
    "for line in file_chi.readlines():\n",
    "    line=line.strip() #remove line break\n",
    "    stop_words_chi.append(line) #update the list of stop words line by line\n",
    "file_chi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eng=open('C:\\\\Users\\\\yuner\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Lib\\\\site-packages\\\\jieba\\\\stop_words_eng.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_eng=[]\n",
    "for line in file_eng.readlines():\n",
    "    line=line.strip() #remove line break\n",
    "    stop_words_eng.append(line) #update the list of stop words line by line\n",
    "file_eng.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Match of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='Facebook将向加密通信转型，打造以隐私为中心的平台。'\n",
    "words=list(jieba.cut(sentence))\n",
    "words_new=[]\n",
    "for word in words:\n",
    "    if word not in stop_words_chi:\n",
    "        words_new.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Facebook', '加密', '通信', '转型', '打造', '隐私', '中心', '平台']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop in the list\n",
    "a=[1,2,3,4,5]\n",
    "b=[i+1 for i in a]           #increase element by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for loop and if statement in the list\n",
    "a=[1,2,3,4,5]\n",
    "b=[i for i in a if i<4]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new=[word for word in list(jieba.cut(sentence)) if word not in stop_words_chi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Facebook', '加密', '通信', '转型', '打造', '隐私', '中心', '平台']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean and tokenize this sentence and remove the stop words\n",
    "sentence='Mr. Zuckerberg, who runs Facebook, Instagram, WhatsApp and Messenger, on Wednesday expressed his intentions to change the essential nature of social media. Instead of encouraging public posts, he said he would focus on private and encrypted communications, in which users message mostly smaller groups of people they know. Unlike publicly shared posts that are kept as users’ permanent records, the communications could also be deleted after a certain period of time.'\n",
    "words_new=[word for word in data_cleaning(sentence).split(' ') if word not in stop_words_eng]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr',\n",
       " '',\n",
       " 'zuckerberg',\n",
       " '',\n",
       " 'runs',\n",
       " 'facebook',\n",
       " '',\n",
       " 'instagram',\n",
       " '',\n",
       " 'whatsapp',\n",
       " 'messenger',\n",
       " '',\n",
       " 'wednesday',\n",
       " 'expressed',\n",
       " 'intentions',\n",
       " 'change',\n",
       " 'essential',\n",
       " 'nature',\n",
       " 'social',\n",
       " 'media',\n",
       " '',\n",
       " 'instead',\n",
       " 'encouraging',\n",
       " 'public',\n",
       " 'posts',\n",
       " '',\n",
       " 'said',\n",
       " 'would',\n",
       " 'focus',\n",
       " 'private',\n",
       " 'encrypted',\n",
       " 'communications',\n",
       " '',\n",
       " 'users',\n",
       " 'message',\n",
       " 'mostly',\n",
       " 'smaller',\n",
       " 'groups',\n",
       " 'people',\n",
       " 'know',\n",
       " '',\n",
       " 'unlike',\n",
       " 'publicly',\n",
       " 'shared',\n",
       " 'posts',\n",
       " 'kept',\n",
       " 'users',\n",
       " '',\n",
       " 'permanent',\n",
       " 'records',\n",
       " '',\n",
       " 'communications',\n",
       " 'could',\n",
       " 'also',\n",
       " 'deleted',\n",
       " 'certain',\n",
       " 'period',\n",
       " 'time',\n",
       " '']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:blue'>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 10 fade-in and fade-out words in speeches.<br>\n",
    "The magnitude of difference is measured by the change in their relative frequencies:<br>\n",
    "<p style='text-align:center;font-size:15px;'>Relative Freq (RF) = word frequency / max word frequency</p>\n",
    "<p style='text-align:center;font-size:15px;'>Difference = RF<font size='2px'>2019</font> - RF<font size='2px'>2009</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options:<br>\n",
    "- Chinese: Annual government work reports, <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2019_Government_Work_Report.txt\">2019</a> vs <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2009_Government_Work_Report.txt\">2009</a>\n",
    "- English: State of the Union address, <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2019_SoU.txt\">2019</a> vs <a href=\"https://juniorworld.github.io/python-workshop-2018/doc/2009_SoU.txt\">2009</a><br>\n",
    "\n",
    "*Hint:*<br>\n",
    "*1. You can use `pd.concat([df1,df2],axis=1)` to combine two data frames by columns*<br>\n",
    "*2. You can use `df.fillna(0)` to replace NAN value with 0.*<br>\n",
    "*3. You can use `df.sort_values(column_name)` to sort a certain column.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  1.000000\n",
       "of                0.333333\n",
       "and               0.166667\n",
       "users             0.166667\n",
       "he                0.166667\n",
       "posts             0.166667\n",
       "on                0.166667\n",
       "communications    0.166667\n",
       "the               0.166667\n",
       "smaller           0.083333\n",
       "be                0.083333\n",
       "could             0.083333\n",
       "mostly            0.083333\n",
       "shared            0.083333\n",
       "wednesday         0.083333\n",
       "intentions        0.083333\n",
       "change            0.083333\n",
       "focus             0.083333\n",
       "certain           0.083333\n",
       "instagram         0.083333\n",
       "private           0.083333\n",
       "records           0.083333\n",
       "are               0.083333\n",
       "deleted           0.083333\n",
       "as                0.083333\n",
       "period            0.083333\n",
       "also              0.083333\n",
       "groups            0.083333\n",
       "kept              0.083333\n",
       "his               0.083333\n",
       "                    ...   \n",
       "a                 0.083333\n",
       "they              0.083333\n",
       "people            0.083333\n",
       "message           0.083333\n",
       "in                0.083333\n",
       "that              0.083333\n",
       "public            0.083333\n",
       "publicly          0.083333\n",
       "to                0.083333\n",
       "media             0.083333\n",
       "runs              0.083333\n",
       "which             0.083333\n",
       "encrypted         0.083333\n",
       "permanent         0.083333\n",
       "know              0.083333\n",
       "whatsapp          0.083333\n",
       "nature            0.083333\n",
       "instead           0.083333\n",
       "encouraging       0.083333\n",
       "zuckerberg        0.083333\n",
       "after             0.083333\n",
       "facebook          0.083333\n",
       "who               0.083333\n",
       "expressed         0.083333\n",
       "mr                0.083333\n",
       "essential         0.083333\n",
       "said              0.083333\n",
       "would             0.083333\n",
       "time              0.083333\n",
       "unlike            0.083333\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=pd.Series(words).value_counts()\n",
    "freq_words/max(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2019=open('doc/2019_Government_Work_Report.txt','r',encoding='utf-8')\n",
    "file_2009=open('doc/2009_Government_Work_Report.txt','r',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHI\n",
    "words_new=[]\n",
    "for line in file_2019.readlines():\n",
    "    line=line.strip()\n",
    "    line=data_cleaning(line)\n",
    "    words=list(jieba.cut(line))\n",
    "    for word in words:\n",
    "        if word not in stop_words_chi:\n",
    "            words_new.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENG\n",
    "words_new=[]\n",
    "for line in file_2019.readlines():\n",
    "    line=line.strip()\n",
    "    line=data_cleaning(line)\n",
    "    words=line.split(' ')\n",
    "    for word in words:\n",
    "        if word not in stop_words_chi:\n",
    "            words_new.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_new_2009=[]\n",
    "for line in file_2009.readlines():\n",
    "    line=line.strip()\n",
    "    line=data_cleaning(line)\n",
    "    words=list(jieba.cut(line))\n",
    "    for word in words:\n",
    "        if word not in stop_words_chi:\n",
    "            words_new_2009.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeff',\n",
       " '代表',\n",
       " ' ',\n",
       " '现在',\n",
       " ' ',\n",
       " '代表',\n",
       " '国务院',\n",
       " ' ',\n",
       " '大会',\n",
       " '作',\n",
       " '政府',\n",
       " '工作',\n",
       " '报告',\n",
       " ' ',\n",
       " '请予',\n",
       " '审议',\n",
       " ' ',\n",
       " '请',\n",
       " '全国政协',\n",
       " '委员',\n",
       " '提出',\n",
       " '意见',\n",
       " ' ',\n",
       " ' ',\n",
       " '年',\n",
       " '工作',\n",
       " '回顾',\n",
       " '年',\n",
       " '极',\n",
       " '平凡',\n",
       " '一年',\n",
       " ' ',\n",
       " '我国',\n",
       " '经济社会',\n",
       " '发展',\n",
       " '经受',\n",
       " '住',\n",
       " '历史',\n",
       " '罕见',\n",
       " '重大',\n",
       " '挑战',\n",
       " '考验',\n",
       " ' ',\n",
       " '中国共产党',\n",
       " '领导',\n",
       " ' ',\n",
       " '全国',\n",
       " '各族人民',\n",
       " '迎难而上',\n",
       " ' ',\n",
       " '奋力拼搏',\n",
       " ' ',\n",
       " '战胜',\n",
       " '艰难险阻',\n",
       " ' ',\n",
       " '改革开放',\n",
       " '社会主义',\n",
       " '现代化',\n",
       " '建设',\n",
       " '取得',\n",
       " '新',\n",
       " '重大成就',\n",
       " ' ',\n",
       " ' ',\n",
       " '国民经济',\n",
       " '继续',\n",
       " '保持',\n",
       " '平稳',\n",
       " '快',\n",
       " '增长',\n",
       " ' ',\n",
       " '国内',\n",
       " '生产总值',\n",
       " '超过',\n",
       " '万亿元',\n",
       " ' ',\n",
       " '上年',\n",
       " '增长',\n",
       " ' ',\n",
       " '物价',\n",
       " '总',\n",
       " '水平',\n",
       " '涨幅',\n",
       " '得到',\n",
       " '控制',\n",
       " ' ',\n",
       " '财政收入',\n",
       " ' ',\n",
       " '万亿元',\n",
       " ' ',\n",
       " '增长',\n",
       " ' ',\n",
       " ' ',\n",
       " '粮食',\n",
       " '连续',\n",
       " '五年',\n",
       " '增产',\n",
       " ' ',\n",
       " '总产量',\n",
       " '万吨',\n",
       " ' ',\n",
       " '创',\n",
       " '历史',\n",
       " '最高',\n",
       " '水平',\n",
       " ' ',\n",
       " ' ',\n",
       " '改革开放',\n",
       " '深入',\n",
       " '推进',\n",
       " ' ',\n",
       " '财税',\n",
       " ' ',\n",
       " '金融',\n",
       " ' ',\n",
       " '价格',\n",
       " ' ',\n",
       " '行政',\n",
       " '管理',\n",
       " '重点',\n",
       " '领域',\n",
       " '关键环节',\n",
       " '改革',\n",
       " '取得',\n",
       " '新',\n",
       " '突破',\n",
       " ' ',\n",
       " '进出口',\n",
       " '贸易总额',\n",
       " ' ',\n",
       " '万亿美元',\n",
       " ' ',\n",
       " '增长',\n",
       " ' ',\n",
       " ' ',\n",
       " '实际',\n",
       " '利用',\n",
       " '外商',\n",
       " '直接',\n",
       " '投资',\n",
       " '亿美元',\n",
       " ' ',\n",
       " ' ',\n",
       " '社会',\n",
       " '事业',\n",
       " '加快',\n",
       " '发展',\n",
       " ' ',\n",
       " '人民',\n",
       " '生活',\n",
       " '进一步',\n",
       " '改善',\n",
       " ' ',\n",
       " '城镇',\n",
       " '新增',\n",
       " '就业',\n",
       " '万人',\n",
       " ' ',\n",
       " '城镇居民',\n",
       " '人均',\n",
       " '可支配',\n",
       " '收入',\n",
       " '元',\n",
       " ' ',\n",
       " '农村居民',\n",
       " '人均',\n",
       " '纯收入',\n",
       " '元',\n",
       " ' ',\n",
       " '实际',\n",
       " '增长',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '全面',\n",
       " '夺取',\n",
       " '抗击',\n",
       " '特大',\n",
       " '自然灾害',\n",
       " '重大胜利',\n",
       " ' ',\n",
       " '成功',\n",
       " '举办',\n",
       " '北京',\n",
       " '奥运会',\n",
       " ' ',\n",
       " '残奥会',\n",
       " ' ',\n",
       " '圆满完成',\n",
       " '神舟',\n",
       " '七号',\n",
       " '载人',\n",
       " '航天',\n",
       " '飞行',\n",
       " ' ',\n",
       " '成就',\n",
       " ' ',\n",
       " '标志',\n",
       " '中国',\n",
       " '特色',\n",
       " '社会主义',\n",
       " '道路',\n",
       " '迈出',\n",
       " '新',\n",
       " '坚实',\n",
       " '步伐',\n",
       " ' ',\n",
       " '极大',\n",
       " '增强',\n",
       " '全国',\n",
       " '各族人民',\n",
       " '战胜',\n",
       " '困难',\n",
       " '勇气',\n",
       " '力量',\n",
       " ' ',\n",
       " '必将',\n",
       " '激励',\n",
       " '新',\n",
       " '历史',\n",
       " '征程',\n",
       " '继续',\n",
       " '奋勇前进',\n",
       " ' ',\n",
       " '一年',\n",
       " ' ',\n",
       " '做',\n",
       " '以下',\n",
       " '主要',\n",
       " '工作',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '及时',\n",
       " '果断',\n",
       " '调整',\n",
       " '宏观经济',\n",
       " '政策',\n",
       " ' ',\n",
       " '全力',\n",
       " '保持',\n",
       " '经济',\n",
       " '平稳',\n",
       " '快',\n",
       " '发展',\n",
       " '正确',\n",
       " '把握',\n",
       " '宏观调控',\n",
       " '方向',\n",
       " ' ',\n",
       " '重点',\n",
       " ' ',\n",
       " '力度',\n",
       " '节奏',\n",
       " ' ',\n",
       " '采取',\n",
       " '一系列',\n",
       " '促进',\n",
       " '经济',\n",
       " '平稳',\n",
       " '快',\n",
       " '发展',\n",
       " '政策措施',\n",
       " ' ',\n",
       " '复杂多变',\n",
       " '形势',\n",
       " ' ',\n",
       " '积极',\n",
       " '应对',\n",
       " '国际',\n",
       " '金融危机',\n",
       " '严重',\n",
       " '冲击',\n",
       " ' ',\n",
       " '努力',\n",
       " '增强',\n",
       " '调控',\n",
       " '预见性',\n",
       " ' ',\n",
       " '针对性',\n",
       " '有效性',\n",
       " ' ',\n",
       " '年',\n",
       " '中',\n",
       " ' ',\n",
       " '国际',\n",
       " '能源',\n",
       " '粮食价格',\n",
       " '处于',\n",
       " '高位',\n",
       " ' ',\n",
       " '世界',\n",
       " '经济',\n",
       " '增长',\n",
       " '放缓',\n",
       " '情况',\n",
       " ' ',\n",
       " '沿海地区',\n",
       " '出现',\n",
       " '出口',\n",
       " '经济',\n",
       " '增速',\n",
       " '下滑',\n",
       " '苗头',\n",
       " ' ',\n",
       " '及时',\n",
       " '宏观调控',\n",
       " '首要任务',\n",
       " '调整',\n",
       " ' ',\n",
       " '保持',\n",
       " '经济',\n",
       " '平稳',\n",
       " '快',\n",
       " '发展',\n",
       " ' ',\n",
       " '控制',\n",
       " '物价',\n",
       " '过快',\n",
       " '上涨',\n",
       " ' ',\n",
       " '采取',\n",
       " '针对性',\n",
       " '财税',\n",
       " '金融',\n",
       " '措施',\n",
       " ' ',\n",
       " '月份',\n",
       " ' ',\n",
       " '国际',\n",
       " '经济',\n",
       " '形势',\n",
       " '急转直下',\n",
       " ' ',\n",
       " '我国',\n",
       " '不利',\n",
       " '影响',\n",
       " '明显',\n",
       " '加重',\n",
       " ' ',\n",
       " '果断',\n",
       " '宏观调控',\n",
       " '着力点',\n",
       " '转',\n",
       " '防止',\n",
       " '经济',\n",
       " '增速',\n",
       " '过快',\n",
       " '下滑',\n",
       " '上来',\n",
       " ' ',\n",
       " '实施',\n",
       " '积极',\n",
       " '财政政策',\n",
       " '适度',\n",
       " '宽松',\n",
       " '货币政策',\n",
       " ' ',\n",
       " '三次',\n",
       " '提高',\n",
       " '出口',\n",
       " '退税率',\n",
       " ' ',\n",
       " '五次',\n",
       " '下调',\n",
       " '金融机构',\n",
       " '存贷款',\n",
       " '基准利率',\n",
       " ' ',\n",
       " '四次',\n",
       " '下调',\n",
       " '存款',\n",
       " '准备金率',\n",
       " ' ',\n",
       " '暂免',\n",
       " '储蓄存款',\n",
       " '利息',\n",
       " '个人所得税',\n",
       " ' ',\n",
       " '下调',\n",
       " '证券交易',\n",
       " '印花税',\n",
       " ' ',\n",
       " '降低',\n",
       " '住房',\n",
       " '交易',\n",
       " '税费',\n",
       " ' ',\n",
       " '加大',\n",
       " '中小企业',\n",
       " '信贷',\n",
       " '支持',\n",
       " ' ',\n",
       " '出手',\n",
       " '快',\n",
       " ' ',\n",
       " '出拳',\n",
       " '要重',\n",
       " ' ',\n",
       " '措施',\n",
       " '要准',\n",
       " ' ',\n",
       " '工作',\n",
       " '要实',\n",
       " '要求',\n",
       " ' ',\n",
       " '迅速',\n",
       " '推出',\n",
       " '进一步',\n",
       " '扩大内需',\n",
       " ' ',\n",
       " '促进',\n",
       " '经济',\n",
       " '增长',\n",
       " '十项',\n",
       " '措施',\n",
       " ' ',\n",
       " '争分夺秒',\n",
       " '落实',\n",
       " ' ',\n",
       " '接连',\n",
       " '出台',\n",
       " '金融',\n",
       " '支持',\n",
       " '经济',\n",
       " '发展',\n",
       " ' ',\n",
       " '促进',\n",
       " '轻纺',\n",
       " '工业',\n",
       " '健康',\n",
       " '发展',\n",
       " ' ',\n",
       " '促进',\n",
       " '房地产',\n",
       " '市场',\n",
       " '健康',\n",
       " '发展',\n",
       " ' ',\n",
       " '搞活流通',\n",
       " '扩大',\n",
       " '消费',\n",
       " '保持',\n",
       " '对外贸易',\n",
       " '稳定增长',\n",
       " ' ',\n",
       " '稳定',\n",
       " '就业',\n",
       " '政策措施',\n",
       " ' ',\n",
       " '加快',\n",
       " '制定',\n",
       " '重点',\n",
       " '产业',\n",
       " '调整',\n",
       " '振兴',\n",
       " '规划',\n",
       " ' ',\n",
       " '措施',\n",
       " '缓解',\n",
       " '经济运行',\n",
       " '中',\n",
       " '突出',\n",
       " '矛盾',\n",
       " ' ',\n",
       " '增强',\n",
       " '信心',\n",
       " ' ',\n",
       " '稳定',\n",
       " '预期',\n",
       " ' ',\n",
       " '保持',\n",
       " '经济',\n",
       " '平稳',\n",
       " '快',\n",
       " '发展',\n",
       " ' ',\n",
       " '发挥',\n",
       " '至关重要',\n",
       " '作用',\n",
       " ' ',\n",
       " '毫不放松',\n",
       " '加强',\n",
       " ' ',\n",
       " '三农',\n",
       " ' ',\n",
       " '工作',\n",
       " ' ',\n",
       " '全年',\n",
       " '中央财政',\n",
       " '用于',\n",
       " ' ',\n",
       " '三农',\n",
       " ' ',\n",
       " '投入',\n",
       " '亿元',\n",
       " ' ',\n",
       " '上年',\n",
       " '增加',\n",
       " '亿元',\n",
       " ' ',\n",
       " '增长',\n",
       " ' ',\n",
       " ' ',\n",
       " '粮食',\n",
       " '直补',\n",
       " ' ',\n",
       " '农资',\n",
       " '综合',\n",
       " '补贴',\n",
       " ' ',\n",
       " '良种',\n",
       " '补贴',\n",
       " ' ',\n",
       " '农机具',\n",
       " '购置',\n",
       " '补贴',\n",
       " '资金',\n",
       " '达',\n",
       " '亿元',\n",
       " ' ',\n",
       " '上年',\n",
       " '增长',\n",
       " '一倍',\n",
       " ' ',\n",
       " '三次',\n",
       " '大幅度提高',\n",
       " '粮食',\n",
       " '最低',\n",
       " '收购价',\n",
       " ' ',\n",
       " '提价',\n",
       " '幅度',\n",
       " '超过',\n",
       " ' ',\n",
       " '实施',\n",
       " '主要',\n",
       " '农产品',\n",
       " '临时',\n",
       " '收储',\n",
       " '政策',\n",
       " ' ',\n",
       " '加强',\n",
       " '耕地',\n",
       " '保护',\n",
       " '农田水利',\n",
       " '建设',\n",
       " ' ',\n",
       " '提高',\n",
       " '农业',\n",
       " '综合',\n",
       " '生产能力',\n",
       " ' ',\n",
       " '扶持',\n",
       " '生猪',\n",
       " ' ',\n",
       " '油料',\n",
       " ' ',\n",
       " '奶业',\n",
       " '发展',\n",
       " ' ',\n",
       " '政策措施',\n",
       " '保护',\n",
       " '调动',\n",
       " '农民',\n",
       " '积极性',\n",
       " ' ',\n",
       " '保障',\n",
       " '重要',\n",
       " '农产品',\n",
       " '供给',\n",
       " ' ',\n",
       " '增加',\n",
       " '农民收入',\n",
       " '方面',\n",
       " '发挥',\n",
       " '重要',\n",
       " '作用',\n",
       " ' ',\n",
       " '稳定',\n",
       " '经济社会',\n",
       " '发展',\n",
       " '全局',\n",
       " '提供',\n",
       " '有力',\n",
       " '支撑',\n",
       " ' ',\n",
       " '坚定不移',\n",
       " '推进',\n",
       " '自主',\n",
       " '创新',\n",
       " '经济',\n",
       " '结构调整',\n",
       " ' ',\n",
       " '实施',\n",
       " '国家',\n",
       " '重大',\n",
       " '科技',\n",
       " '专项',\n",
       " ' ',\n",
       " '信息',\n",
       " ' ',\n",
       " '生物',\n",
       " ' ',\n",
       " '环保',\n",
       " '领域',\n",
       " '新建',\n",
       " '一批',\n",
       " '国家',\n",
       " '工程',\n",
       " '中心',\n",
       " ' ',\n",
       " '重点',\n",
       " '实验室',\n",
       " '企业',\n",
       " '技术',\n",
       " '中心',\n",
       " ' ',\n",
       " '成功',\n",
       " '研发',\n",
       " '支线',\n",
       " '飞机',\n",
       " ' ',\n",
       " '新能源',\n",
       " '汽车',\n",
       " ' ',\n",
       " '高速铁路',\n",
       " '一批',\n",
       " '关键技术',\n",
       " '重大',\n",
       " '装备',\n",
       " ' ',\n",
       " '中央财政',\n",
       " '科技',\n",
       " '投入',\n",
       " '亿元',\n",
       " ' ',\n",
       " '增长',\n",
       " ' ',\n",
       " ' ',\n",
       " '电信',\n",
       " ' ',\n",
       " '航空',\n",
       " '行业',\n",
       " '重组',\n",
       " '迈出',\n",
       " '重要',\n",
       " '步伐',\n",
       " ' ',\n",
       " '继续',\n",
       " '淘汰',\n",
       " '落后',\n",
       " '产能',\n",
       " ' ',\n",
       " '全年',\n",
       " '关停',\n",
       " '火电',\n",
       " '万千瓦',\n",
       " ' ',\n",
       " '关闭',\n",
       " '煤矿',\n",
       " '处',\n",
       " ' ',\n",
       " '加大',\n",
       " '基础设施',\n",
       " '基础产业',\n",
       " '投资',\n",
       " '力度',\n",
       " ' ',\n",
       " '能源',\n",
       " ' ',\n",
       " '交通',\n",
       " ' ',\n",
       " '水利',\n",
       " '方面',\n",
       " '建成',\n",
       " '开工',\n",
       " '一批',\n",
       " '重大项目',\n",
       " ' ',\n",
       " '扎实',\n",
       " '推进',\n",
       " '区域',\n",
       " '发展',\n",
       " '总体',\n",
       " '战略',\n",
       " ' ',\n",
       " '区域',\n",
       " '经济',\n",
       " '发展',\n",
       " '协调性',\n",
       " '增强',\n",
       " ' ',\n",
       " '坚持不懈',\n",
       " '推动',\n",
       " '节能',\n",
       " '减排',\n",
       " '生态',\n",
       " '环境保护',\n",
       " ' ',\n",
       " '中央财政',\n",
       " '安排',\n",
       " '亿元',\n",
       " '资金',\n",
       " ' ',\n",
       " '支持',\n",
       " '十大',\n",
       " '重点',\n",
       " '节能',\n",
       " '工程',\n",
       " '环保',\n",
       " '设施',\n",
       " '项目',\n",
       " '建设',\n",
       " ' ',\n",
       " '全国',\n",
       " '新增',\n",
       " '城市污水',\n",
       " '日',\n",
       " '处理',\n",
       " '能力',\n",
       " '万吨',\n",
       " ' ',\n",
       " '新增',\n",
       " '燃煤',\n",
       " '脱硫',\n",
       " '机组',\n",
       " '容量',\n",
       " '万千瓦',\n",
       " ' ',\n",
       " '单位',\n",
       " '国内',\n",
       " '生产总值',\n",
       " '能耗',\n",
       " '上年',\n",
       " '下降',\n",
       " ' ',\n",
       " ' ',\n",
       " '化学',\n",
       " '需氧量',\n",
       " ' ',\n",
       " '二氧化硫',\n",
       " '排放量',\n",
       " '减少',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '近三年',\n",
       " '累计',\n",
       " ' ',\n",
       " '单位',\n",
       " '国内',\n",
       " '生产总值',\n",
       " '能耗',\n",
       " '下降',\n",
       " ' ',\n",
       " ' ',\n",
       " '化学',\n",
       " '需氧量',\n",
       " ' ',\n",
       " '二氧化硫',\n",
       " '排放量',\n",
       " '减少',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '巩固',\n",
       " '退耕还林',\n",
       " '草',\n",
       " '成果',\n",
       " ' ',\n",
       " '推进',\n",
       " '天然林',\n",
       " ' ',\n",
       " '青海',\n",
       " '三江',\n",
       " '源',\n",
       " '生态',\n",
       " '保护',\n",
       " '建设工程',\n",
       " ' ',\n",
       " '实施',\n",
       " '重点',\n",
       " '流域',\n",
       " ' ',\n",
       " '区域',\n",
       " '水污染',\n",
       " '防治规划',\n",
       " ' ',\n",
       " '发布',\n",
       " ' ',\n",
       " '中国',\n",
       " '应对',\n",
       " '气候变化',\n",
       " '政策',\n",
       " '行动',\n",
       " ' ',\n",
       " '白皮书',\n",
       " ' ',\n",
       " ' ',\n",
       " '二',\n",
       " ' ',\n",
       " '统筹',\n",
       " '经济社会',\n",
       " '发展',\n",
       " ' ',\n",
       " '全面',\n",
       " '加强',\n",
       " '改善',\n",
       " '民生',\n",
       " '重点',\n",
       " '社会',\n",
       " '建设',\n",
       " '就业',\n",
       " '社会保障',\n",
       " '工作',\n",
       " '进一步',\n",
       " '加强',\n",
       " ' ',\n",
       " '完善',\n",
       " '促进',\n",
       " '就业',\n",
       " ' ',\n",
       " '创业',\n",
       " '带动',\n",
       " '就业',\n",
       " '政策',\n",
       " ' ',\n",
       " '落实',\n",
       " '最低工资',\n",
       " '制度',\n",
       " ' ',\n",
       " '各项',\n",
       " '社会保险',\n",
       " '覆盖面',\n",
       " '继续',\n",
       " '扩大',\n",
       " ' ',\n",
       " '城镇职工',\n",
       " '基本',\n",
       " '养老保险',\n",
       " ' ',\n",
       " '基本',\n",
       " '医疗保险',\n",
       " '参保',\n",
       " '人数',\n",
       " '增加',\n",
       " '万',\n",
       " '万',\n",
       " ' ',\n",
       " '失业',\n",
       " ' ',\n",
       " '工伤',\n",
       " ' ',\n",
       " '生育',\n",
       " '保险',\n",
       " '参保',\n",
       " '人数',\n",
       " '继续',\n",
       " '增加',\n",
       " ' ',\n",
       " '企业',\n",
       " '退休',\n",
       " '人员',\n",
       " '养老金',\n",
       " '人均',\n",
       " '每月',\n",
       " '新增',\n",
       " '元',\n",
       " ' ',\n",
       " '启动',\n",
       " '事业单位',\n",
       " '基本',\n",
       " '养老保险',\n",
       " '制度',\n",
       " '改革',\n",
       " '试点',\n",
       " ' ',\n",
       " '积极探索',\n",
       " '建立',\n",
       " '新型农村',\n",
       " '社会',\n",
       " '养老保险',\n",
       " '制度',\n",
       " ' ',\n",
       " '农民工',\n",
       " ' ',\n",
       " '征地',\n",
       " '农民',\n",
       " '社会保障',\n",
       " '工作',\n",
       " '稳步',\n",
       " '推进',\n",
       " ' ',\n",
       " '全面',\n",
       " '加强',\n",
       " '城乡居民',\n",
       " '最低',\n",
       " '生活',\n",
       " '保障制度',\n",
       " '建设',\n",
       " ' ',\n",
       " '救助',\n",
       " '人数',\n",
       " '达到',\n",
       " '万人',\n",
       " ' ',\n",
       " '及时',\n",
       " '增加',\n",
       " '低收入',\n",
       " '群体',\n",
       " '大学生',\n",
       " '生活',\n",
       " '补贴',\n",
       " ' ',\n",
       " '大幅度提高',\n",
       " '重点',\n",
       " '优抚对象',\n",
       " '抚恤',\n",
       " '优待',\n",
       " '标准',\n",
       " ' ',\n",
       " '加大',\n",
       " '保障性',\n",
       " '住房',\n",
       " '建设',\n",
       " '棚户区',\n",
       " '改造',\n",
       " '力度',\n",
       " ' ',\n",
       " '低收入',\n",
       " '群众',\n",
       " '住房',\n",
       " '困难',\n",
       " '问题',\n",
       " '得到',\n",
       " '一定',\n",
       " '程度',\n",
       " '缓解',\n",
       " ' ',\n",
       " '解决',\n",
       " '多万',\n",
       " '农村',\n",
       " '人口',\n",
       " '饮水',\n",
       " '安全',\n",
       " '问题',\n",
       " ' ',\n",
       " '促进',\n",
       " '教育',\n",
       " '公平',\n",
       " '取得',\n",
       " '新进展',\n",
       " ' ',\n",
       " '全面',\n",
       " '实行',\n",
       " '城乡',\n",
       " '免费',\n",
       " '义务教育',\n",
       " ' ',\n",
       " '农村',\n",
       " '义务教育',\n",
       " '阶段',\n",
       " '学生',\n",
       " '免费',\n",
       " '提供',\n",
       " '教科书',\n",
       " ' ',\n",
       " '提高',\n",
       " '中西部',\n",
       " '地区',\n",
       " '校舍',\n",
       " '维修',\n",
       " '标准',\n",
       " ' ',\n",
       " '国家',\n",
       " '财政',\n",
       " '安排',\n",
       " ' ',\n",
       " '亿元',\n",
       " '帮助',\n",
       " '解决',\n",
       " '北方',\n",
       " '农村',\n",
       " '中小学',\n",
       " '取暖',\n",
       " '问题',\n",
       " ' ',\n",
       " '职业',\n",
       " '教育',\n",
       " '加快',\n",
       " '发展',\n",
       " ' ',\n",
       " '国家',\n",
       " '助学',\n",
       " '制度',\n",
       " '进一步',\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_new_2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_2019=pd.Series(words_new).value_counts()\n",
    "freq_2009=pd.Series(words_new_2009).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_freq_2019=freq_2019/max(freq_2019)\n",
    "relative_freq_2009=freq_2009/max(freq_2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuner\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "relative_freq=pd.concat([relative_freq_2019,relative_freq_2009],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_freq=relative_freq.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_freq['diff']=relative_freq[0]-relative_freq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_freq.columns=['2019','2009','diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019</th>\n",
       "      <th>2009</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>习近平</th>\n",
       "      <td>0.006341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>风险</th>\n",
       "      <td>0.008780</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>供给</th>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.007151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>新</th>\n",
       "      <td>0.023415</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.009145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>推动</th>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.010556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>五年</th>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.010649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>改革</th>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.011866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>创新</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.014116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>全面</th>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.014199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>中国</th>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.014946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         2019      2009      diff\n",
       "习近平  0.006341  0.000000  0.006341\n",
       "风险   0.008780  0.001712  0.007068\n",
       "供给   0.008293  0.001142  0.007151\n",
       "新    0.023415  0.014269  0.009145\n",
       "推动   0.015122  0.004566  0.010556\n",
       "五年   0.011220  0.000571  0.010649\n",
       "改革   0.040976  0.029110  0.011866\n",
       "创新   0.024390  0.010274  0.014116\n",
       "全面   0.023902  0.009703  0.014199\n",
       "中国   0.019512  0.004566  0.014946"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq.sort_values('diff').tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
