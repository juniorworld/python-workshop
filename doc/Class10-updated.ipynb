{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://juniorworld.github.io/python-workshop-2018/img/portfolio/week10.jpg\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a model to give predictions based on **labeled data** (X + Y)\n",
    "- Information Retrieval: KNN\n",
    "- Regression: \n",
    "    - Linear regression\n",
    "    - Generalize Linear Model: logistic (binary), poisson (count)\n",
    "- Classification:\n",
    "    - Binary Classification: Naive Bayesian classifier\n",
    "    - Multiclass Classification: Multinomial Bayesian classifier, KNN\n",
    "    - (Advanced) Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure:\n",
    "- STEP 1: Split dataset\n",
    "    - 2 parts: train vs test, e.g. 60:40 or 70:30\n",
    "    - 3 parts: train vs test vs validation: e.g. 60:30:10 or 70:20:10 [not usual]\n",
    "- STEP 2: Train the model\n",
    "- STEP 3: Test the model\n",
    "- STEP 4: Parameter tuning. If the result is not satisfactory, retrain the model with new parameters and retest the newly trained model.\n",
    "- STEP 5: Report the model performance with Test/Validation data.\n",
    "- STEP 6: Apply the model to new data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)\n",
    "- Distance-based Spatial Voting Model\n",
    "- Purpose: Retrieve the most similar information from database + Classify a new point according its nearest neighbors\n",
    "- Input: a set of data with labels\n",
    "- Output: K nearest neighbors\n",
    "    - Assign the category according K's labels\n",
    "- Parameter: K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Movie|#Fight scenes|#Kiss scenes|Genre|\n",
    "|-----|:-----------:|:----------:|:---:|\n",
    "|California Man|3|104|Love|\n",
    "|He's not that into you|2|100|Love|\n",
    "|Beautiful Woman|1|81|Love|\n",
    "|Kevin Longblade|101|10|Action|\n",
    "|Robo Slayer 3000|99|5|Action|\n",
    "|Amped II|98|2|Action|\n",
    "|<font style='color:blue'>XXXXX</font>|<font style='color:blue'>18</font>|<font style='color:blue'>90</font>|<font style='color:red'>?</font>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=np.random.choice(range(150),100,replace=False)\n",
    "train_X=iris.data[train_index]      #extract 100 data records as our training data\n",
    "train_Y=iris.target[train_index]    #training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index=[i for i in range(150) if i not in train_index]\n",
    "test_X=iris.data[test_index]\n",
    "test_Y=iris.target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(50, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6. , 2.9, 4.5, 1.5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0] #first data point in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X[0] #first test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance between first test data and first train data\n",
    "distance=np.linalg.norm(test_X[0]-train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.531288716601915"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances between first test data and ALL train data\n",
    "distances=[]\n",
    "for i in train_X:\n",
    "    distance=np.linalg.norm(test_X[0]-i)\n",
    "    distances.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose K=4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort([2,1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65, 26, 14, 98], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(distances)[:4] #extract the indexes of K smallest distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the labels of those points\n",
    "KNNs=train_Y[np.argsort(distances)[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5\n",
       "5    2\n",
       "2    2\n",
       "1    2\n",
       "3    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4,5,5,4,4,4,4,2,1]\n",
    "pd.Series(a).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the most frequent label and use it as your predicted label for first testing point\n",
    "pd.Series(KNNs).value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a for loop to go over every testing data and predict their labels\n",
    "predict_Y=[]\n",
    "for j in test_X:\n",
    "    distances=[]\n",
    "    for i in train_X:\n",
    "        distance=np.linalg.norm(j-i)\n",
    "        distances.append(distance)\n",
    "    KNN_index=np.argsort(distances)[:4]\n",
    "    KNNs=train_Y[KNN_index]\n",
    "    y=pd.Series(KNNs).value_counts().index[0]\n",
    "    predict_Y.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance diagnosis\n",
    "- **Accuracy** rate: \n",
    "    - formula: true predictions/total sample size\n",
    "- **Precision** rate:\n",
    "    - formula: true positive/predicted positive\n",
    "    - **macro**: calculate the precision of each label and get their means\n",
    "    - micro: sum up the number of true positive and get the total precision [= accuracy]\n",
    "- **Recall** rate:\n",
    "    - formula: true positive/real positive\n",
    "    - **macro**\n",
    "    - micro\n",
    "- **F1** score\n",
    "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/057ffc6b4fa80dc1c0e1f2f1f6b598c38cdd7c23'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis=pd.crosstab(np.array(predict_Y),test_Y, rownames=['predict'], colnames=['real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>real</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "real      0   1   2\n",
       "predict            \n",
       "0        18   0   0\n",
       "1         0  13   1\n",
       "2         0   0  18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 13, 18], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diagonal(diagnosis) #extract numbers on diagnonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metric1: ACC\n",
    "accuracy_rate=sum(np.diagonal(diagnosis))/len(predict_Y)\n",
    "accuracy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904763"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metric2: precision\n",
    "precisions=np.diagonal(diagnosis)/np.sum(diagnosis,axis=1) #diagnoals in row sums\n",
    "precision_rate=np.mean(precisions)\n",
    "precision_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metric3: recall\n",
    "recalls=np.diagonal(diagnosis)/np.sum(diagnosis,axis=0) #diagnoals in col sums\n",
    "recall_rate=np.mean(recalls)\n",
    "recall_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786453119786453"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metric4: F1\n",
    "f1s=2*precisions*recalls/(precisions+recalls)\n",
    "F1=np.mean(f1s)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.9761904761904763\n",
      "0.9824561403508771\n",
      "0.9786453119786453\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_Y, predict_Y))\n",
    "print(precision_score(test_Y, predict_Y, average='macro'))\n",
    "print(recall_score(test_Y, predict_Y, average='macro'))\n",
    "print(f1_score(test_Y, predict_Y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_Y, predict_Y))\n",
    "print(precision_score(test_Y, predict_Y, average='micro'))\n",
    "print(recall_score(test_Y, predict_Y, average='micro'))\n",
    "print(f1_score(test_Y, predict_Y, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "Set K=6. Please apply KNN technique to digit data:\n",
    "1. Split the data into training set (1000 samples) and testing set (797 samples).\n",
    "2. Apply KNN\n",
    "3. Report model performance metrics (accuracy, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITE YOUR CODE HERE\n",
    "train_index=np.random.choice(range(1797),1000,replace=False)\n",
    "train_X=digits.data[train_index]      #extract 100 data records as our training data\n",
    "train_Y=digits.target[train_index]   \n",
    "\n",
    "test_index=[i for i in range(1797) if i not in train_index]\n",
    "test_X=digits.data[test_index]\n",
    "test_Y=digits.target[test_index]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_Y=[]\n",
    "for j in test_X:\n",
    "    distances=[]\n",
    "    for i in train_X:\n",
    "        distance=np.linalg.norm(j-i)\n",
    "        distances.append(distance)\n",
    "    KNN_index=np.argsort(distances)[:6]\n",
    "    KNNs=train_Y[KNN_index]\n",
    "    y=pd.Series(KNNs).value_counts().index[0]\n",
    "    predict_Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972396486825596\n",
      "0.9733726787749613\n",
      "0.9725595238095238\n",
      "0.9720897126628149\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_Y, predict_Y))\n",
    "print(precision_score(test_Y, predict_Y, average='macro'))\n",
    "print(recall_score(test_Y, predict_Y, average='macro'))\n",
    "print(f1_score(test_Y, predict_Y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['dem','rep','dem','rep','dem','dem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unqiue_labels=list(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_num=[]\n",
    "for label in labels:\n",
    "    labels_num.append(unqiue_labels.index(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "- Purpose: find the best parameter\n",
    "- For KNN, the only parameter is K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap previous lines into a function\n",
    "def KNN(K,train_X,train_Y,test_X,test_Y):\n",
    "    predict_Y=[]\n",
    "    for j in test_X:\n",
    "        distances=[]\n",
    "        for i in train_X:\n",
    "            distance=np.linalg.norm(j-i)\n",
    "            distances.append(distance)\n",
    "        KNN_index=np.argsort(distances)[:K]\n",
    "        KNNs=train_Y[KNN_index]\n",
    "        y=pd.Series(KNNs).value_counts().index[0]\n",
    "        predict_Y.append(y)\n",
    "    predict_Y=np.array(predict_Y)\n",
    "    return(predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s=[]\n",
    "for K in range(1,10):\n",
    "    predict_Y=KNN(K,train_X,train_Y,test_X,test_Y)\n",
    "    f1s.append(f1_score(test_Y, predict_Y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.982381858108638,\n",
       " 0.9773558686173729,\n",
       " 0.9811926273632473,\n",
       " 0.9723463773774018,\n",
       " 0.9723150334233359,\n",
       " 0.9720897126628149,\n",
       " 0.9710123114098834,\n",
       " 0.969552431351873,\n",
       " 0.9710697234172816]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s #K=1, nearest neighbor can inform us more accurately about labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df=pd.read_csv('doc/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Production Budget (millions)</th>\n",
       "      <th>Box Office (millions)</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Rating IMDB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>Action</td>\n",
       "      <td>237</td>\n",
       "      <td>2784</td>\n",
       "      <td>11.7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Blind Side</td>\n",
       "      <td>Drama</td>\n",
       "      <td>29</td>\n",
       "      <td>309</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chronicles of Narnia: The Lion, the Witch ...</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>180</td>\n",
       "      <td>745</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Action</td>\n",
       "      <td>185</td>\n",
       "      <td>1005</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ET: The Extra-Terrestrial</td>\n",
       "      <td>Drama</td>\n",
       "      <td>11</td>\n",
       "      <td>793</td>\n",
       "      <td>75.5</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Movie      Genre  \\\n",
       "0                                             Avatar     Action   \n",
       "1                                     The Blind Side      Drama   \n",
       "2  The Chronicles of Narnia: The Lion, the Witch ...  Adventure   \n",
       "3                                    The Dark Knight     Action   \n",
       "4                          ET: The Extra-Terrestrial      Drama   \n",
       "\n",
       "   Production Budget (millions)  Box Office (millions)   ROI  Rating IMDB  \n",
       "0                           237                   2784  11.7          8.0  \n",
       "1                            29                    309  10.7          7.6  \n",
       "2                           180                    745   4.1          6.9  \n",
       "3                           185                   1005   5.4          9.0  \n",
       "4                            11                    793  75.5          7.9  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(movie_df['Genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=np.random.choice(range(movie_df.shape[0]),20,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=movie_df.iloc[train_index,2:].get_values()\n",
    "train_Y=movie_df.iloc[train_index,1].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index=[i for i in range(movie_df.shape[0]) if i not in train_index]\n",
    "test_X=movie_df.iloc[test_index,2:].get_values()\n",
    "test_Y=movie_df.iloc[test_index,1].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Drama', 'Adventure', 'Action', 'Drama', 'Action', 'Adventure'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN(1,train_X,train_Y,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Drama', 'Adventure', 'Adventure', 'Adventure',\n",
       "       'Thriller/Suspense', 'Action'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Break\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://cdn-images-1.medium.com/max/900/1*XMId5sJqPtm8-RIwVVz2tg.png' width='300px' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree is a non-parametric supervised learning method.\n",
    "- [Advanced] Random Forest\n",
    "- STEP 1: Calculate the entropy of labels\n",
    "- STEP 2: Choose a variable and split the dataset along that variable\n",
    "- STEP 3: Calculate the entropy of splitting\n",
    "- STEP 4: Repeat STEP 2-3 for all variables\n",
    "- STEP 5: Find the variable with greatest information gain\n",
    "- STEP 6: Add it to the root\n",
    "- STEP 7: Repeat STEP 2-6 for all variables\n",
    "- STEP 8: Build up the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "- Entropy: Information load\n",
    "    - formula: <img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/7de5d59a442f5305853d4392826b1f51dc43f6d0' width='200px'>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    freq=pd.Series(data).value_counts()\n",
    "    freq=freq/sum(freq)\n",
    "    H=sum(-freq*np.log2(freq))\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[2,2,2,2,2,2,2,2] #one group\n",
    "b=[1,1,1,1,2,2,2,2] #two balanced group\n",
    "c=[1,2,2,2,2,2,2,2] #two unbalanced group\n",
    "Ha=entropy(a)\n",
    "Hb=entropy(b)\n",
    "Hc=entropy(c)\n",
    "print(Ha)\n",
    "print(Hb)\n",
    "print(Hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to what degree one variable can inform us about another variable\n",
    "var1=['red','blue','red','blue']\n",
    "var2=[0,1,1,1]\n",
    "df=pd.DataFrame({'color':var1,'number':var2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into two parts and check the entropy of 'number'\n",
    "H1=entropy(df[df['color']=='red']['number'])\n",
    "H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2=entropy(df[df['color']=='blue']['number']) #exteremly certain\n",
    "H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=H1+H2 #integrated entropy for two groups\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "iris_df['label']=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use threshold of sepal length at 5.0 first and find out the entropy of this splitting\n",
    "threshold=5\n",
    "H1=entropy(iris_df[iris_df['sepal length (cm)']>=threshold]['label'])\n",
    "H2=entropy(iris_df[iris_df['sepal length (cm)']<threshold]['label'])\n",
    "H1+H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.iloc[:,0] #reference by column index, rather than column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the threshold that can produce minimal entropy\n",
    "def best_threshold(data,col): #col is the column index that you want to apply threshold searching\n",
    "    thresholds=np.unique(data.iloc[:,col]) #threshold candidates\n",
    "    Hs=[]\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        #WRITE YOUR CODE HERE\n",
    "    \n",
    "    best_threshold=                 #best threshold is the one with minimal entropy\n",
    "    min_Hs=min(Hs)\n",
    "    return(best_threshold,min_Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run over all columns and find out the best feature with smallest entropy\n",
    "Hs=[]\n",
    "thresholds=[]\n",
    "for i in range(4):\n",
    "    threshold,H=best_threshold(iris_df,i)\n",
    "    thresholds.append(threshold)\n",
    "    Hs.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(Hs) #the root feature is petal length as it has the smallest entropy -> it can inform us about labels at most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature(data):\n",
    "    Hs=[]\n",
    "    thresholds=[]\n",
    "    for i in range(4):\n",
    "        threshold,H=best_threshold(data,i)\n",
    "        thresholds.append(threshold)\n",
    "        Hs.append(H)\n",
    "    return(np.argmin(Hs),thresholds[np.argmin(Hs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build up Decision Tree\n",
    "- RULE: Assign the feature according to their entropy in ascending order\n",
    "- Create a dictionary about Tree:\n",
    "    - Four elements\n",
    "    - 'col' is the column index used at current level\n",
    "    - 'threshold' is its threshold\n",
    "    - 'greater' contains a dictionary about its child leaf for data points greater than the threshold\n",
    "    - 'smaller' contains a dictionary about its child leaf for data points smaller than the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python\n",
    "{'col':2,\n",
    " 'threshold':thresholds[2],\n",
    " 'larger':{ #containing a dictionary for child leaf where data points greater than threshold will go\n",
    "     'col': ..., \n",
    "     'threshold': ...,\n",
    "     'larger': ...,\n",
    "     'smaller': ...\n",
    " }, \n",
    " 'smaller':{ #containing a dictionary for child leaf where data points smaller than threshold will go\n",
    "     'col': ..., \n",
    "     'threshold': ...,\n",
    "     'larger': ...,\n",
    "     'smaller': ...\n",
    " }  \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(data,max_group_size):\n",
    "    if len(np.unique(data['label']))>1 and data.shape[0]>max_group_size:\n",
    "        feature,threshold=best_feature(data)\n",
    "        feature_name=data.columns[feature]\n",
    "        tree_dict={'col':feature,'threshold':threshold}\n",
    "        #split dataset into two parts: larger and smaller than threshold\n",
    "        #this is the larger part\n",
    "        subset1=data[data[feature_name]>=threshold]\n",
    "        if subset1.shape[0] == data.shape[0]: #check whether dataset is really split into two part\n",
    "            return(data['label'].value_counts().index[0])\n",
    "        tree_dict['larger']=create_tree(subset1,max_group_size)\n",
    "        #this is the smaller part\n",
    "        subset2=data[data[feature_name]<threshold]\n",
    "        if subset2.shape[0] == data.shape[0]:\n",
    "            return(data['label'].value_counts().index[0])\n",
    "        tree_dict['smaller']=create_tree(subset2,max_group_size)\n",
    "        return(tree_dict)\n",
    "    else:\n",
    "        return(data['label'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iris=iris_df.sample(n=100)\n",
    "test_iris=iris_df.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict=create_tree(train_iris,50)\n",
    "tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dict=create_tree(train_iris,30)\n",
    "tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tree(point,tree,predicts):\n",
    "    if point[tree['col']]>=tree['threshold']:\n",
    "        if np.isscalar(tree['larger']):\n",
    "            predicts.append(tree['larger'])\n",
    "        else:\n",
    "            apply_tree(point,tree['larger'],predicts)\n",
    "    else:\n",
    "        if np.isscalar(tree['smaller']):\n",
    "            predicts.append(tree['smaller'])\n",
    "        else:\n",
    "            apply_tree(point,tree['smaller'],predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=[]\n",
    "for i in range(test_iris.shape[0]):\n",
    "    apply_tree(test_iris.iloc[i],tree_dict,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predicts,test_iris['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
